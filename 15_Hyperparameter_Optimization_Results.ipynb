{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_Hyperparameter_Optimization_Results.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/redcican/Master-Thesis/blob/master/15_Hyperparameter_Optimization_Results.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "q6We0LWzyKZU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Result of 4 different Methods to tune the Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "RJHV179YyS8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "collapsed": true,
        "outputId": "e28b5e01-fdb3-45d1-d02a-8d72acf16822"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/redcican/Master-Thesis/master/car.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-26 11:10:31--  https://raw.githubusercontent.com/redcican/Master-Thesis/master/car.csv\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25973 (25K) [text/plain]\n",
            "Saving to: ‘car.csv.1’\n",
            "\n",
            "car.csv.1           100%[===================>]  25.36K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2018-06-26 11:10:31 (1.71 MB/s) - ‘car.csv.1’ saved [25973/25973]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QNPqU6i5ygP-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6bJ2fPeypre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "897f8e2e-a21e-4405-eb60-414a17782761"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('car.csv')\n",
        "print(df.shape)\n",
        "type(df)  # pandas.core.frame.DataFrame.\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1728, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bying</th>\n",
              "      <th>Maint</th>\n",
              "      <th>Doors</th>\n",
              "      <th>Persons</th>\n",
              "      <th>Lug_Boot</th>\n",
              "      <th>Safety</th>\n",
              "      <th>Class_Val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Bying  Maint  Doors  Persons  Lug_Boot  Safety  Class_Val\n",
              "0      4      4      2        2         1       1          1\n",
              "1      4      4      2        2         1       2          1\n",
              "2      4      4      2        2         1       3          1\n",
              "3      4      4      2        2         2       1          1\n",
              "4      4      4      2        2         2       2          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "UIVplvuXywJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c94b45d-4a8b-45d5-db2e-957f2fbee974"
      },
      "cell_type": "code",
      "source": [
        "X = df.values[:,:-1]\n",
        "y = pd.get_dummies(df['Class_Val']).values\n",
        "print(X.shape,y.shape)\n",
        "input_dim = X.shape[1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1728, 6), (1728, 4))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Za_LGCaFyzeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2401d84b-7178-409c-985d-5c0044da4fd1"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1382, 6), (1382, 4), (346, 6), (346, 4))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFw26HOhzhfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3IGXqtik2JT9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(model, X, y):\n",
        "    y_pred = model.predict_classes(X, verbose=0)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(pd.DataFrame(confusion_matrix(y, y_pred)), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_ABkwnRyT7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.Grid Search"
      ]
    },
    {
      "metadata": {
        "id": "c5_SKTbHyV7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "collapsed": true,
        "outputId": "3c6b59b4-aab2-4dc8-f2e8-793244a0bed2"
      },
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(256, input_dim=input_dim, activation='relu',kernel_initializer='he_normal'))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(256, activation='relu',kernel_initializer='he_normal'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(4, activation='softmax',kernel_initializer='he_normal'))\n",
        "model_1.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='Nadam',\n",
        "        metrics=['accuracy'])\n",
        "model_1_history=model_1.fit(X_train,y_train, batch_size=16,epochs=100,validation_data=(X_test,y_test),verbose=2 )"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1382 samples, validate on 346 samples\n",
            "Epoch 1/100\n",
            " - 1s - loss: 1.0916 - acc: 0.6664 - val_loss: 0.5512 - val_acc: 0.7832\n",
            "Epoch 2/100\n",
            " - 0s - loss: 0.6278 - acc: 0.7337 - val_loss: 0.5446 - val_acc: 0.7399\n",
            "Epoch 3/100\n",
            " - 0s - loss: 0.5116 - acc: 0.7656 - val_loss: 0.4064 - val_acc: 0.8353\n",
            "Epoch 4/100\n",
            " - 0s - loss: 0.4668 - acc: 0.8075 - val_loss: 0.3654 - val_acc: 0.8728\n",
            "Epoch 5/100\n",
            " - 0s - loss: 0.4271 - acc: 0.8075 - val_loss: 0.3083 - val_acc: 0.8757\n",
            "Epoch 6/100\n",
            " - 0s - loss: 0.4015 - acc: 0.8292 - val_loss: 0.2957 - val_acc: 0.8757\n",
            "Epoch 7/100\n",
            " - 0s - loss: 0.3901 - acc: 0.8329 - val_loss: 0.2803 - val_acc: 0.8960\n",
            "Epoch 8/100\n",
            " - 0s - loss: 0.3582 - acc: 0.8423 - val_loss: 0.3172 - val_acc: 0.8555\n",
            "Epoch 9/100\n",
            " - 0s - loss: 0.3275 - acc: 0.8553 - val_loss: 0.3529 - val_acc: 0.8237\n",
            "Epoch 10/100\n",
            " - 0s - loss: 0.3221 - acc: 0.8705 - val_loss: 0.2554 - val_acc: 0.8988\n",
            "Epoch 11/100\n",
            " - 0s - loss: 0.3138 - acc: 0.8611 - val_loss: 0.2394 - val_acc: 0.8873\n",
            "Epoch 12/100\n",
            " - 0s - loss: 0.3096 - acc: 0.8698 - val_loss: 0.2562 - val_acc: 0.8902\n",
            "Epoch 13/100\n",
            " - 0s - loss: 0.2644 - acc: 0.8849 - val_loss: 0.2234 - val_acc: 0.8873\n",
            "Epoch 14/100\n",
            " - 0s - loss: 0.2839 - acc: 0.8763 - val_loss: 0.2405 - val_acc: 0.8931\n",
            "Epoch 15/100\n",
            " - 0s - loss: 0.2494 - acc: 0.8922 - val_loss: 0.2472 - val_acc: 0.8786\n",
            "Epoch 16/100\n",
            " - 0s - loss: 0.2606 - acc: 0.8842 - val_loss: 0.2329 - val_acc: 0.8988\n",
            "Epoch 17/100\n",
            " - 0s - loss: 0.2433 - acc: 0.8915 - val_loss: 0.1980 - val_acc: 0.9133\n",
            "Epoch 18/100\n",
            " - 0s - loss: 0.2277 - acc: 0.9074 - val_loss: 0.2616 - val_acc: 0.8786\n",
            "Epoch 19/100\n",
            " - 0s - loss: 0.2448 - acc: 0.9001 - val_loss: 0.2012 - val_acc: 0.9306\n",
            "Epoch 20/100\n",
            " - 0s - loss: 0.2354 - acc: 0.8973 - val_loss: 0.2006 - val_acc: 0.9249\n",
            "Epoch 21/100\n",
            " - 0s - loss: 0.2183 - acc: 0.9016 - val_loss: 0.1991 - val_acc: 0.9191\n",
            "Epoch 22/100\n",
            " - 0s - loss: 0.2150 - acc: 0.9067 - val_loss: 0.1897 - val_acc: 0.9191\n",
            "Epoch 23/100\n",
            " - 0s - loss: 0.1987 - acc: 0.9204 - val_loss: 0.2043 - val_acc: 0.9249\n",
            "Epoch 24/100\n",
            " - 0s - loss: 0.2045 - acc: 0.9103 - val_loss: 0.1789 - val_acc: 0.9306\n",
            "Epoch 25/100\n",
            " - 0s - loss: 0.2094 - acc: 0.9059 - val_loss: 0.1765 - val_acc: 0.9277\n",
            "Epoch 26/100\n",
            " - 0s - loss: 0.2018 - acc: 0.9139 - val_loss: 0.1831 - val_acc: 0.9277\n",
            "Epoch 27/100\n",
            " - 0s - loss: 0.1854 - acc: 0.9139 - val_loss: 0.1785 - val_acc: 0.9220\n",
            "Epoch 28/100\n",
            " - 0s - loss: 0.1865 - acc: 0.9305 - val_loss: 0.1900 - val_acc: 0.9162\n",
            "Epoch 29/100\n",
            " - 0s - loss: 0.1727 - acc: 0.9219 - val_loss: 0.1828 - val_acc: 0.9162\n",
            "Epoch 30/100\n",
            " - 0s - loss: 0.1769 - acc: 0.9313 - val_loss: 0.1678 - val_acc: 0.9335\n",
            "Epoch 31/100\n",
            " - 0s - loss: 0.1765 - acc: 0.9197 - val_loss: 0.1700 - val_acc: 0.9335\n",
            "Epoch 32/100\n",
            " - 0s - loss: 0.1721 - acc: 0.9247 - val_loss: 0.1494 - val_acc: 0.9364\n",
            "Epoch 33/100\n",
            " - 0s - loss: 0.1667 - acc: 0.9211 - val_loss: 0.1831 - val_acc: 0.9162\n",
            "Epoch 34/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 0s - loss: 0.1642 - acc: 0.9262 - val_loss: 0.1566 - val_acc: 0.9277\n",
            "Epoch 35/100\n",
            " - 0s - loss: 0.1766 - acc: 0.9233 - val_loss: 0.2160 - val_acc: 0.9104\n",
            "Epoch 36/100\n",
            " - 0s - loss: 0.1808 - acc: 0.9269 - val_loss: 0.1823 - val_acc: 0.9306\n",
            "Epoch 37/100\n",
            " - 0s - loss: 0.1669 - acc: 0.9284 - val_loss: 0.1523 - val_acc: 0.9422\n",
            "Epoch 38/100\n",
            " - 0s - loss: 0.1609 - acc: 0.9334 - val_loss: 0.1500 - val_acc: 0.9364\n",
            "Epoch 39/100\n",
            " - 0s - loss: 0.1629 - acc: 0.9305 - val_loss: 0.1501 - val_acc: 0.9509\n",
            "Epoch 40/100\n",
            " - 0s - loss: 0.1485 - acc: 0.9356 - val_loss: 0.1656 - val_acc: 0.9451\n",
            "Epoch 41/100\n",
            " - 0s - loss: 0.1419 - acc: 0.9356 - val_loss: 0.1534 - val_acc: 0.9393\n",
            "Epoch 42/100\n",
            " - 0s - loss: 0.1580 - acc: 0.9276 - val_loss: 0.1410 - val_acc: 0.9451\n",
            "Epoch 43/100\n",
            " - 0s - loss: 0.1348 - acc: 0.9450 - val_loss: 0.1605 - val_acc: 0.9422\n",
            "Epoch 44/100\n",
            " - 0s - loss: 0.1448 - acc: 0.9378 - val_loss: 0.1570 - val_acc: 0.9335\n",
            "Epoch 45/100\n",
            " - 0s - loss: 0.1440 - acc: 0.9385 - val_loss: 0.2021 - val_acc: 0.9133\n",
            "Epoch 46/100\n",
            " - 0s - loss: 0.1480 - acc: 0.9334 - val_loss: 0.1372 - val_acc: 0.9566\n",
            "Epoch 47/100\n",
            " - 0s - loss: 0.1382 - acc: 0.9407 - val_loss: 0.1395 - val_acc: 0.9306\n",
            "Epoch 48/100\n",
            " - 0s - loss: 0.1328 - acc: 0.9493 - val_loss: 0.1715 - val_acc: 0.9335\n",
            "Epoch 49/100\n",
            " - 0s - loss: 0.1387 - acc: 0.9378 - val_loss: 0.1556 - val_acc: 0.9335\n",
            "Epoch 50/100\n",
            " - 0s - loss: 0.1285 - acc: 0.9363 - val_loss: 0.1468 - val_acc: 0.9480\n",
            "Epoch 51/100\n",
            " - 0s - loss: 0.1475 - acc: 0.9363 - val_loss: 0.1248 - val_acc: 0.9422\n",
            "Epoch 52/100\n",
            " - 0s - loss: 0.1083 - acc: 0.9486 - val_loss: 0.1384 - val_acc: 0.9451\n",
            "Epoch 53/100\n",
            " - 0s - loss: 0.1123 - acc: 0.9522 - val_loss: 0.1600 - val_acc: 0.9335\n",
            "Epoch 54/100\n",
            " - 0s - loss: 0.1283 - acc: 0.9443 - val_loss: 0.1355 - val_acc: 0.9451\n",
            "Epoch 55/100\n",
            " - 0s - loss: 0.1197 - acc: 0.9544 - val_loss: 0.1291 - val_acc: 0.9509\n",
            "Epoch 56/100\n",
            " - 0s - loss: 0.1235 - acc: 0.9392 - val_loss: 0.1164 - val_acc: 0.9538\n",
            "Epoch 57/100\n",
            " - 0s - loss: 0.1105 - acc: 0.9508 - val_loss: 0.1279 - val_acc: 0.9595\n",
            "Epoch 58/100\n",
            " - 0s - loss: 0.1146 - acc: 0.9559 - val_loss: 0.1540 - val_acc: 0.9306\n",
            "Epoch 59/100\n",
            " - 0s - loss: 0.1083 - acc: 0.9522 - val_loss: 0.1578 - val_acc: 0.9451\n",
            "Epoch 60/100\n",
            " - 0s - loss: 0.1151 - acc: 0.9530 - val_loss: 0.1206 - val_acc: 0.9422\n",
            "Epoch 61/100\n",
            " - 0s - loss: 0.1156 - acc: 0.9493 - val_loss: 0.1141 - val_acc: 0.9538\n",
            "Epoch 62/100\n",
            " - 0s - loss: 0.1278 - acc: 0.9436 - val_loss: 0.1420 - val_acc: 0.9480\n",
            "Epoch 63/100\n",
            " - 0s - loss: 0.1032 - acc: 0.9595 - val_loss: 0.1079 - val_acc: 0.9509\n",
            "Epoch 64/100\n",
            " - 0s - loss: 0.1170 - acc: 0.9486 - val_loss: 0.1431 - val_acc: 0.9509\n",
            "Epoch 65/100\n",
            " - 0s - loss: 0.1120 - acc: 0.9493 - val_loss: 0.1380 - val_acc: 0.9422\n",
            "Epoch 66/100\n",
            " - 0s - loss: 0.0998 - acc: 0.9580 - val_loss: 0.1186 - val_acc: 0.9480\n",
            "Epoch 67/100\n",
            " - 0s - loss: 0.0937 - acc: 0.9667 - val_loss: 0.1540 - val_acc: 0.9364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 68/100\n",
            " - 0s - loss: 0.1071 - acc: 0.9559 - val_loss: 0.1428 - val_acc: 0.9393\n",
            "Epoch 69/100\n",
            " - 0s - loss: 0.0995 - acc: 0.9580 - val_loss: 0.1312 - val_acc: 0.9538\n",
            "Epoch 70/100\n",
            " - 0s - loss: 0.1053 - acc: 0.9515 - val_loss: 0.1143 - val_acc: 0.9653\n",
            "Epoch 71/100\n",
            " - 0s - loss: 0.1114 - acc: 0.9522 - val_loss: 0.1250 - val_acc: 0.9538\n",
            "Epoch 72/100\n",
            " - 0s - loss: 0.0950 - acc: 0.9616 - val_loss: 0.1296 - val_acc: 0.9538\n",
            "Epoch 73/100\n",
            " - 0s - loss: 0.1045 - acc: 0.9631 - val_loss: 0.1090 - val_acc: 0.9538\n",
            "Epoch 74/100\n",
            " - 0s - loss: 0.1004 - acc: 0.9551 - val_loss: 0.1259 - val_acc: 0.9480\n",
            "Epoch 75/100\n",
            " - 0s - loss: 0.0858 - acc: 0.9711 - val_loss: 0.1354 - val_acc: 0.9509\n",
            "Epoch 76/100\n",
            " - 0s - loss: 0.1055 - acc: 0.9588 - val_loss: 0.1150 - val_acc: 0.9624\n",
            "Epoch 77/100\n",
            " - 0s - loss: 0.0933 - acc: 0.9595 - val_loss: 0.1256 - val_acc: 0.9422\n",
            "Epoch 78/100\n",
            " - 0s - loss: 0.0952 - acc: 0.9624 - val_loss: 0.1137 - val_acc: 0.9624\n",
            "Epoch 79/100\n",
            " - 0s - loss: 0.0913 - acc: 0.9595 - val_loss: 0.1114 - val_acc: 0.9538\n",
            "Epoch 80/100\n",
            " - 0s - loss: 0.0977 - acc: 0.9616 - val_loss: 0.1297 - val_acc: 0.9509\n",
            "Epoch 81/100\n",
            " - 0s - loss: 0.0850 - acc: 0.9616 - val_loss: 0.1137 - val_acc: 0.9566\n",
            "Epoch 82/100\n",
            " - 0s - loss: 0.0689 - acc: 0.9732 - val_loss: 0.0990 - val_acc: 0.9538\n",
            "Epoch 83/100\n",
            " - 0s - loss: 0.0731 - acc: 0.9732 - val_loss: 0.1174 - val_acc: 0.9566\n",
            "Epoch 84/100\n",
            " - 0s - loss: 0.0749 - acc: 0.9689 - val_loss: 0.1066 - val_acc: 0.9566\n",
            "Epoch 85/100\n",
            " - 0s - loss: 0.0896 - acc: 0.9602 - val_loss: 0.1045 - val_acc: 0.9682\n",
            "Epoch 86/100\n",
            " - 0s - loss: 0.0794 - acc: 0.9660 - val_loss: 0.1038 - val_acc: 0.9595\n",
            "Epoch 87/100\n",
            " - 0s - loss: 0.0930 - acc: 0.9624 - val_loss: 0.0913 - val_acc: 0.9740\n",
            "Epoch 88/100\n",
            " - 0s - loss: 0.0823 - acc: 0.9718 - val_loss: 0.1143 - val_acc: 0.9509\n",
            "Epoch 89/100\n",
            " - 0s - loss: 0.1029 - acc: 0.9624 - val_loss: 0.0920 - val_acc: 0.9624\n",
            "Epoch 90/100\n",
            " - 0s - loss: 0.0740 - acc: 0.9711 - val_loss: 0.1189 - val_acc: 0.9595\n",
            "Epoch 91/100\n",
            " - 0s - loss: 0.0827 - acc: 0.9660 - val_loss: 0.1155 - val_acc: 0.9595\n",
            "Epoch 92/100\n",
            " - 0s - loss: 0.0680 - acc: 0.9740 - val_loss: 0.1227 - val_acc: 0.9624\n",
            "Epoch 93/100\n",
            " - 0s - loss: 0.0926 - acc: 0.9580 - val_loss: 0.0847 - val_acc: 0.9769\n",
            "Epoch 94/100\n",
            " - 0s - loss: 0.0629 - acc: 0.9740 - val_loss: 0.0938 - val_acc: 0.9624\n",
            "Epoch 95/100\n",
            " - 0s - loss: 0.0906 - acc: 0.9631 - val_loss: 0.1193 - val_acc: 0.9566\n",
            "Epoch 96/100\n",
            " - 0s - loss: 0.0816 - acc: 0.9689 - val_loss: 0.0894 - val_acc: 0.9682\n",
            "Epoch 97/100\n",
            " - 0s - loss: 0.0660 - acc: 0.9703 - val_loss: 0.1067 - val_acc: 0.9653\n",
            "Epoch 98/100\n",
            " - 0s - loss: 0.0792 - acc: 0.9711 - val_loss: 0.0928 - val_acc: 0.9595\n",
            "Epoch 99/100\n",
            " - 0s - loss: 0.0694 - acc: 0.9682 - val_loss: 0.0934 - val_acc: 0.9653\n",
            "Epoch 100/100\n",
            " - 0s - loss: 0.0587 - acc: 0.9747 - val_loss: 0.0889 - val_acc: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lqz75diZ1HY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3a01a1d7-8d4b-49c7-d948-dc1a7c7a246c"
      },
      "cell_type": "code",
      "source": [
        "model_1_train_score = model_1.evaluate(X_train,y_train,verbose=0)\n",
        "model_1_score = model_1.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Train loss: \",model_1_train_score[0])\n",
        "print(\"Test loss: \",model_1_score[0])\n",
        "print(\"Train accuracy: %.4f%%\"% (model_1_train_score[1]*100))\n",
        "print(\"Test accuracy: %.4f%%\"%(model_1_score[1]*100))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train loss: ', 0.030188280978064353)\n",
            "('Test loss: ', 0.08891730044424706)\n",
            "Train accuracy: 98.9870%\n",
            "Test accuracy: 97.1098%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QitWU8xj1l24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "8c5f82b4-7669-4d2d-a1d6-4bae5eaf4ff0"
      },
      "cell_type": "code",
      "source": [
        "y_pred_class = model_1.predict_classes(X_test,verbose=0)\n",
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "plot_confusion_matrix(model_1, X_test, y_test_class)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.98      0.99      0.99       240\n",
            "          1       0.96      0.92      0.94        79\n",
            "          2       0.89      1.00      0.94        17\n",
            "          3       1.00      0.80      0.89        10\n",
            "\n",
            "avg / total       0.97      0.97      0.97       346\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFlCAYAAACXw4MtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwwlSbn3/wA3dUXrD4LkUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f506090a550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "g0Uq4WO33XTq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Random Search"
      ]
    },
    {
      "metadata": {
        "id": "clfAGAww2Ms7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "collapsed": true,
        "outputId": "142c1b99-35eb-400b-9cfd-2198f42d0aac"
      },
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(64, input_dim=input_dim, activation='tanh',kernel_initializer='he_uniform'))\n",
        "model_2.add(Dropout(0.0))\n",
        "model_2.add(Dense(8, activation='tanh',kernel_initializer='he_uniform'))\n",
        "model_2.add(Dropout(0.0))\n",
        "model_2.add(Dense(4, activation='softmax',kernel_initializer='he_uniform'))\n",
        "model_2.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='Adadelta',\n",
        "        metrics=['accuracy'])\n",
        "model_2_history=model_2.fit(X_train,y_train, batch_size=128,epochs=100,validation_data=(X_test,y_test),verbose=2 )"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1382 samples, validate on 346 samples\n",
            "Epoch 1/100\n",
            " - 1s - loss: 0.9981 - acc: 0.6946 - val_loss: 0.9480 - val_acc: 0.6936\n",
            "Epoch 2/100\n",
            " - 0s - loss: 0.9106 - acc: 0.7019 - val_loss: 0.8896 - val_acc: 0.6936\n",
            "Epoch 3/100\n",
            " - 0s - loss: 0.8641 - acc: 0.7019 - val_loss: 0.8531 - val_acc: 0.6936\n",
            "Epoch 4/100\n",
            " - 0s - loss: 0.8338 - acc: 0.7019 - val_loss: 0.8266 - val_acc: 0.6936\n",
            "Epoch 5/100\n",
            " - 0s - loss: 0.8085 - acc: 0.7019 - val_loss: 0.7992 - val_acc: 0.6936\n",
            "Epoch 6/100\n",
            " - 0s - loss: 0.7831 - acc: 0.7019 - val_loss: 0.7717 - val_acc: 0.6936\n",
            "Epoch 7/100\n",
            " - 0s - loss: 0.7581 - acc: 0.7026 - val_loss: 0.7431 - val_acc: 0.6965\n",
            "Epoch 8/100\n",
            " - 0s - loss: 0.7316 - acc: 0.7077 - val_loss: 0.7190 - val_acc: 0.6965\n",
            "Epoch 9/100\n",
            " - 0s - loss: 0.7052 - acc: 0.7135 - val_loss: 0.6917 - val_acc: 0.7139\n",
            "Epoch 10/100\n",
            " - 0s - loss: 0.6839 - acc: 0.7207 - val_loss: 0.6693 - val_acc: 0.7399\n",
            "Epoch 11/100\n",
            " - 0s - loss: 0.6625 - acc: 0.7308 - val_loss: 0.6510 - val_acc: 0.7659\n",
            "Epoch 12/100\n",
            " - 0s - loss: 0.6422 - acc: 0.7424 - val_loss: 0.6316 - val_acc: 0.7254\n",
            "Epoch 13/100\n",
            " - 0s - loss: 0.6258 - acc: 0.7446 - val_loss: 0.6076 - val_acc: 0.7630\n",
            "Epoch 14/100\n",
            " - 0s - loss: 0.6064 - acc: 0.7605 - val_loss: 0.5928 - val_acc: 0.7428\n",
            "Epoch 15/100\n",
            " - 0s - loss: 0.5912 - acc: 0.7598 - val_loss: 0.5751 - val_acc: 0.7919\n",
            "Epoch 16/100\n",
            " - 0s - loss: 0.5770 - acc: 0.7721 - val_loss: 0.5564 - val_acc: 0.7890\n",
            "Epoch 17/100\n",
            " - 0s - loss: 0.5625 - acc: 0.7822 - val_loss: 0.5467 - val_acc: 0.7717\n",
            "Epoch 18/100\n",
            " - 0s - loss: 0.5527 - acc: 0.7808 - val_loss: 0.5257 - val_acc: 0.7919\n",
            "Epoch 19/100\n",
            " - 0s - loss: 0.5258 - acc: 0.7808 - val_loss: 0.5022 - val_acc: 0.8035\n",
            "Epoch 20/100\n",
            " - 0s - loss: 0.5018 - acc: 0.7952 - val_loss: 0.4941 - val_acc: 0.7977\n",
            "Epoch 21/100\n",
            " - 0s - loss: 0.4862 - acc: 0.7952 - val_loss: 0.4770 - val_acc: 0.8179\n",
            "Epoch 22/100\n",
            " - 0s - loss: 0.4706 - acc: 0.8148 - val_loss: 0.4502 - val_acc: 0.8150\n",
            "Epoch 23/100\n",
            " - 0s - loss: 0.4568 - acc: 0.8133 - val_loss: 0.4735 - val_acc: 0.7775\n",
            "Epoch 24/100\n",
            " - 0s - loss: 0.4476 - acc: 0.8104 - val_loss: 0.4319 - val_acc: 0.8208\n",
            "Epoch 25/100\n",
            " - 0s - loss: 0.4310 - acc: 0.8249 - val_loss: 0.4226 - val_acc: 0.8295\n",
            "Epoch 26/100\n",
            " - 0s - loss: 0.4174 - acc: 0.8300 - val_loss: 0.4195 - val_acc: 0.8150\n",
            "Epoch 27/100\n",
            " - 0s - loss: 0.4194 - acc: 0.8242 - val_loss: 0.3993 - val_acc: 0.8382\n",
            "Epoch 28/100\n",
            " - 0s - loss: 0.3972 - acc: 0.8430 - val_loss: 0.4038 - val_acc: 0.8266\n",
            "Epoch 29/100\n",
            " - 0s - loss: 0.3981 - acc: 0.8372 - val_loss: 0.3843 - val_acc: 0.8497\n",
            "Epoch 30/100\n",
            " - 0s - loss: 0.3916 - acc: 0.8401 - val_loss: 0.3807 - val_acc: 0.8439\n",
            "Epoch 31/100\n",
            " - 0s - loss: 0.3870 - acc: 0.8415 - val_loss: 0.3677 - val_acc: 0.8555\n",
            "Epoch 32/100\n",
            " - 0s - loss: 0.3740 - acc: 0.8502 - val_loss: 0.3730 - val_acc: 0.8584\n",
            "Epoch 33/100\n",
            " - 0s - loss: 0.3608 - acc: 0.8538 - val_loss: 0.3611 - val_acc: 0.8584\n",
            "Epoch 34/100\n",
            " - 0s - loss: 0.3560 - acc: 0.8647 - val_loss: 0.3557 - val_acc: 0.8584\n",
            "Epoch 35/100\n",
            " - 0s - loss: 0.3446 - acc: 0.8712 - val_loss: 0.3933 - val_acc: 0.8121\n",
            "Epoch 36/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 0s - loss: 0.3465 - acc: 0.8647 - val_loss: 0.3448 - val_acc: 0.8584\n",
            "Epoch 37/100\n",
            " - 0s - loss: 0.3308 - acc: 0.8705 - val_loss: 0.3419 - val_acc: 0.8671\n",
            "Epoch 38/100\n",
            " - 0s - loss: 0.3247 - acc: 0.8792 - val_loss: 0.3236 - val_acc: 0.8786\n",
            "Epoch 39/100\n",
            " - 0s - loss: 0.3148 - acc: 0.8777 - val_loss: 0.3368 - val_acc: 0.8584\n",
            "Epoch 40/100\n",
            " - 0s - loss: 0.3060 - acc: 0.8828 - val_loss: 0.3061 - val_acc: 0.8931\n",
            "Epoch 41/100\n",
            " - 0s - loss: 0.3053 - acc: 0.8857 - val_loss: 0.3021 - val_acc: 0.8931\n",
            "Epoch 42/100\n",
            " - 0s - loss: 0.2995 - acc: 0.8842 - val_loss: 0.3000 - val_acc: 0.8873\n",
            "Epoch 43/100\n",
            " - 0s - loss: 0.3021 - acc: 0.8806 - val_loss: 0.3103 - val_acc: 0.8931\n",
            "Epoch 44/100\n",
            " - 0s - loss: 0.2952 - acc: 0.8864 - val_loss: 0.2917 - val_acc: 0.9017\n",
            "Epoch 45/100\n",
            " - 0s - loss: 0.2829 - acc: 0.8951 - val_loss: 0.3046 - val_acc: 0.8931\n",
            "Epoch 46/100\n",
            " - 0s - loss: 0.2824 - acc: 0.8958 - val_loss: 0.2889 - val_acc: 0.8960\n",
            "Epoch 47/100\n",
            " - 0s - loss: 0.2797 - acc: 0.8987 - val_loss: 0.2808 - val_acc: 0.9017\n",
            "Epoch 48/100\n",
            " - 0s - loss: 0.2784 - acc: 0.8944 - val_loss: 0.3037 - val_acc: 0.8902\n",
            "Epoch 49/100\n",
            " - 0s - loss: 0.2742 - acc: 0.8980 - val_loss: 0.2815 - val_acc: 0.8988\n",
            "Epoch 50/100\n",
            " - 0s - loss: 0.2678 - acc: 0.9023 - val_loss: 0.2702 - val_acc: 0.9017\n",
            "Epoch 51/100\n",
            " - 0s - loss: 0.2572 - acc: 0.9059 - val_loss: 0.2683 - val_acc: 0.8931\n",
            "Epoch 52/100\n",
            " - 0s - loss: 0.2590 - acc: 0.9016 - val_loss: 0.2685 - val_acc: 0.8873\n",
            "Epoch 53/100\n",
            " - 0s - loss: 0.2610 - acc: 0.8973 - val_loss: 0.2688 - val_acc: 0.8988\n",
            "Epoch 54/100\n",
            " - 0s - loss: 0.2546 - acc: 0.9052 - val_loss: 0.2627 - val_acc: 0.8844\n",
            "Epoch 55/100\n",
            " - 0s - loss: 0.2527 - acc: 0.9009 - val_loss: 0.2594 - val_acc: 0.9191\n",
            "Epoch 56/100\n",
            " - 0s - loss: 0.2407 - acc: 0.9074 - val_loss: 0.2575 - val_acc: 0.8902\n",
            "Epoch 57/100\n",
            " - 0s - loss: 0.2415 - acc: 0.9124 - val_loss: 0.2740 - val_acc: 0.8902\n",
            "Epoch 58/100\n",
            " - 0s - loss: 0.2498 - acc: 0.9045 - val_loss: 0.2647 - val_acc: 0.8960\n",
            "Epoch 59/100\n",
            " - 0s - loss: 0.2391 - acc: 0.9038 - val_loss: 0.2689 - val_acc: 0.9104\n",
            "Epoch 60/100\n",
            " - 0s - loss: 0.2339 - acc: 0.9132 - val_loss: 0.2465 - val_acc: 0.9017\n",
            "Epoch 61/100\n",
            " - 0s - loss: 0.2295 - acc: 0.9146 - val_loss: 0.2427 - val_acc: 0.9075\n",
            "Epoch 62/100\n",
            " - 0s - loss: 0.2284 - acc: 0.9168 - val_loss: 0.2459 - val_acc: 0.9191\n",
            "Epoch 63/100\n",
            " - 0s - loss: 0.2303 - acc: 0.9096 - val_loss: 0.2491 - val_acc: 0.8988\n",
            "Epoch 64/100\n",
            " - 0s - loss: 0.2302 - acc: 0.9117 - val_loss: 0.2619 - val_acc: 0.9017\n",
            "Epoch 65/100\n",
            " - 0s - loss: 0.2295 - acc: 0.9088 - val_loss: 0.2589 - val_acc: 0.9046\n",
            "Epoch 66/100\n",
            " - 0s - loss: 0.2205 - acc: 0.9219 - val_loss: 0.2390 - val_acc: 0.9191\n",
            "Epoch 67/100\n",
            " - 0s - loss: 0.2371 - acc: 0.9103 - val_loss: 0.2358 - val_acc: 0.9220\n",
            "Epoch 68/100\n",
            " - 0s - loss: 0.2173 - acc: 0.9175 - val_loss: 0.2320 - val_acc: 0.9191\n",
            "Epoch 69/100\n",
            " - 0s - loss: 0.2130 - acc: 0.9190 - val_loss: 0.2433 - val_acc: 0.9017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 70/100\n",
            " - 0s - loss: 0.2105 - acc: 0.9226 - val_loss: 0.2274 - val_acc: 0.9191\n",
            "Epoch 71/100\n",
            " - 0s - loss: 0.2154 - acc: 0.9204 - val_loss: 0.2259 - val_acc: 0.9162\n",
            "Epoch 72/100\n",
            " - 0s - loss: 0.2060 - acc: 0.9204 - val_loss: 0.2269 - val_acc: 0.9133\n",
            "Epoch 73/100\n",
            " - 0s - loss: 0.2045 - acc: 0.9305 - val_loss: 0.2289 - val_acc: 0.9104\n",
            "Epoch 74/100\n",
            " - 0s - loss: 0.2088 - acc: 0.9226 - val_loss: 0.2239 - val_acc: 0.9162\n",
            "Epoch 75/100\n",
            " - 0s - loss: 0.2041 - acc: 0.9219 - val_loss: 0.2335 - val_acc: 0.9017\n",
            "Epoch 76/100\n",
            " - 0s - loss: 0.2018 - acc: 0.9226 - val_loss: 0.2182 - val_acc: 0.9191\n",
            "Epoch 77/100\n",
            " - 0s - loss: 0.2077 - acc: 0.9211 - val_loss: 0.2241 - val_acc: 0.9162\n",
            "Epoch 78/100\n",
            " - 0s - loss: 0.2049 - acc: 0.9240 - val_loss: 0.2209 - val_acc: 0.9162\n",
            "Epoch 79/100\n",
            " - 0s - loss: 0.2024 - acc: 0.9204 - val_loss: 0.2288 - val_acc: 0.9162\n",
            "Epoch 80/100\n",
            " - 0s - loss: 0.1947 - acc: 0.9291 - val_loss: 0.2174 - val_acc: 0.9162\n",
            "Epoch 81/100\n",
            " - 0s - loss: 0.1940 - acc: 0.9298 - val_loss: 0.2338 - val_acc: 0.9046\n",
            "Epoch 82/100\n",
            " - 0s - loss: 0.1996 - acc: 0.9240 - val_loss: 0.2134 - val_acc: 0.9191\n",
            "Epoch 83/100\n",
            " - 0s - loss: 0.1948 - acc: 0.9240 - val_loss: 0.2288 - val_acc: 0.9017\n",
            "Epoch 84/100\n",
            " - 0s - loss: 0.1977 - acc: 0.9291 - val_loss: 0.2143 - val_acc: 0.9191\n",
            "Epoch 85/100\n",
            " - 0s - loss: 0.1927 - acc: 0.9284 - val_loss: 0.2123 - val_acc: 0.9220\n",
            "Epoch 86/100\n",
            " - 0s - loss: 0.1919 - acc: 0.9276 - val_loss: 0.2162 - val_acc: 0.9075\n",
            "Epoch 87/100\n",
            " - 0s - loss: 0.1916 - acc: 0.9226 - val_loss: 0.2146 - val_acc: 0.9133\n",
            "Epoch 88/100\n",
            " - 0s - loss: 0.1861 - acc: 0.9334 - val_loss: 0.2114 - val_acc: 0.9220\n",
            "Epoch 89/100\n",
            " - 0s - loss: 0.1848 - acc: 0.9334 - val_loss: 0.2072 - val_acc: 0.9249\n",
            "Epoch 90/100\n",
            " - 0s - loss: 0.1864 - acc: 0.9276 - val_loss: 0.2260 - val_acc: 0.9104\n",
            "Epoch 91/100\n",
            " - 0s - loss: 0.1889 - acc: 0.9327 - val_loss: 0.2130 - val_acc: 0.9191\n",
            "Epoch 92/100\n",
            " - 0s - loss: 0.1867 - acc: 0.9320 - val_loss: 0.2121 - val_acc: 0.9075\n",
            "Epoch 93/100\n",
            " - 0s - loss: 0.1781 - acc: 0.9385 - val_loss: 0.2093 - val_acc: 0.9162\n",
            "Epoch 94/100\n",
            " - 0s - loss: 0.1813 - acc: 0.9320 - val_loss: 0.2062 - val_acc: 0.9249\n",
            "Epoch 95/100\n",
            " - 0s - loss: 0.1766 - acc: 0.9370 - val_loss: 0.2018 - val_acc: 0.9249\n",
            "Epoch 96/100\n",
            " - 0s - loss: 0.1866 - acc: 0.9349 - val_loss: 0.2027 - val_acc: 0.9220\n",
            "Epoch 97/100\n",
            " - 0s - loss: 0.1765 - acc: 0.9349 - val_loss: 0.2003 - val_acc: 0.9249\n",
            "Epoch 98/100\n",
            " - 0s - loss: 0.1787 - acc: 0.9363 - val_loss: 0.2010 - val_acc: 0.9249\n",
            "Epoch 99/100\n",
            " - 0s - loss: 0.1771 - acc: 0.9334 - val_loss: 0.1977 - val_acc: 0.9220\n",
            "Epoch 100/100\n",
            " - 0s - loss: 0.1733 - acc: 0.9363 - val_loss: 0.2112 - val_acc: 0.9162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T6xOJK2h4Rbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "86eb20fb-ec4b-47a6-8ab7-4abbe05fb757"
      },
      "cell_type": "code",
      "source": [
        "model_2_train_score = model_2.evaluate(X_train,y_train,verbose=0)\n",
        "model_2_score = model_2.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Train loss: \",model_2_train_score[0])\n",
        "print(\"Test loss: \",model_2_score[0])\n",
        "print(\"Train accuracy: %.4f%%\"% (model_2_train_score[1]*100))\n",
        "print(\"Test accuracy: %.4f%%\"%(model_2_score[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train loss: ', 0.18144990611880715)\n",
            "('Test loss: ', 0.21116091956982033)\n",
            "Train accuracy: 92.4023%\n",
            "Test accuracy: 91.6185%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hcHHhh1G4bFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "30474839-405f-4269-a2f0-aec54905463b"
      },
      "cell_type": "code",
      "source": [
        "y_pred_class = model_2.predict_classes(X_test,verbose=0)\n",
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "plot_confusion_matrix(model_2, X_test, y_test_class)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.98      0.97      0.97       240\n",
            "          1       0.89      0.90      0.89        79\n",
            "          2       0.76      0.76      0.76        17\n",
            "          3       0.82      0.90      0.86        10\n",
            "\n",
            "avg / total       0.94      0.94      0.94       346\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFlCAYAAACXw4MtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAH2VJREFUeJzt3XmYXHWd7/F3dXVn62CSTpokJECH\nEH8YwlVulCWIIIosLuMwiKNR8YJKBkERuRomyKayyabIMKAgCnFG1CCiCGjABUZCQCEC8jNAFiBr\n09n3rq75o5vQ10k63OpzclJ13q/nqYeuU9Wnvjmc1Cfnt51CuVxGkqQ8q8u6AEmSsmYYSpJyzzCU\nJOWeYShJyj3DUJKUe4ahJCn36tP+gIOOmercjZTd/M33MG6fkVmXUdP61NdRKvXJuoyaVyy2Uyql\n/rWUaw0NYwpp7bvpjSf36vu+7W/fT622HfGskyQlYtw+e2RdQsUMQ0lSIp6btyTrEipmGEqSElGo\n4mEohqEkKRGFgmEoScq5fcdU70A+w1CSlIjn5y/NuoSKGYaSpGQUMpsZ0WuGoSQpEQ6gkSTlngNo\nJEm5t++YEVmXUDHDUJKUCAfQSJJkn6EkKe/sM5Qk5Z5hKEnKvX1bhmddQsUMQ0lSIp6fvzzrEipm\nGEqSElFwBRpJUt7ZZyhJyr2xLbtnXULFDENJUiJeWNCadQkVMwwlSYlwoW5JkgxDSVLeOYBGkpR7\nY1uGZV1CxQxDSVIiXljQlnUJFTMMJUmJcACNJCn3XIFGkpR7hqEkKff2cQCNJCnv5jmARpKUdw6g\nkSTlnpPuJUm5N2bvoVmXUDHDUJKUiPkLV2RdQsUMQ0lSIuwzrEJnnnocb5nQQrFYx60/+i2vtK3h\nzE8dT3upxJYt7VxwxR2sXLWOUye/i0lvfSMUCjw861lu+Y8Hsi69qs2Y8Wt+efdvtz5/+unneeTR\n/8yuoBp1+eU3MmfOX4ECU6dO4YADQtYl1RyP8TbYZ1hdJr55H/ZpGc6pX7iBQbsN4LZ/+xxPP7uQ\nC79xB4uWtPGpye/ig8e9jfsefJJ9u95XV1fgju9+kZ/fN5vWtjVZ/xGq1gknHM0JJxwNwGOzn+L+\n+x7OuKLaM3v2HBYseJnp06/l+ecXcv75VzN9+rVZl1VTPMbbVvMDaEIIA4ERXU8XxxjXpVdS+v78\nl3k8/eyLAKxZt4H+/RqYdul/0NFRBqB52Bt48ukFLF66gnO//kMAdhvYn3JHmXXrN2VWd6258cYf\ncellZ2ddRs2ZNesJjjrqUADGjt2L1avXsnbtOgYObMy4strhMd62MXsPzrqEivUYhiGEtwLfAgYD\nrUAB2COE8DLw2RjjX9IvMXkdHWU2btoCwAeOeRsPPxrp6ChzyFvfyDn/8n7mvbicX83889b3nz3l\n/Rx95P/imzf9kg0bN2dVdk156qm5jBg+jGHDhmRdSs1pbV3B+PHjtj4fMmQQra0rcv9FnSSP8bbN\nX7gq6xIqtqNr2muBU2KM42OM74gxHh5jHAucBVyffnnpeseh4/nAsW/lG9ffBcAjj/2NE0+9igUv\nLuPkDx+x9X1X//vdnPSpq/n4h45gj+F+eSdhxk9/zQc+eFTWZeRCuVzOuoSa5zHuVKCuV48s7ejT\n62KMz/79xhjjn4BiOiXtHIdMHMf/+cg7Oeu877Fu/SaOnLT/1tceeOgp3rx/C7s3D+JN40YBsGbt\nBp58ej7jw+isSq4pjz32FG95y35Zl1GTmpubaG19bVms5cvbaG5uyrCi2uMx3o5CoXePDO2oz/CR\nEMLPgZ8By7u2jQBOBH6XZmFpahzQlzM/dTxnTP0uq9dsAODTH383Ly9pY+4Li5kQ9mLhS60MGdTI\nl8/8IKeedQNlyuw3bhR33vNoxtVXv2XL2hjQvx8NDQ1Zl1KTJk2ayPXX38ZJJ72XZ56ZS3NzE42N\nA7Iuq6Z4jLdjJwRaCOEK4HA68+tSYDZwG50XaIuBj8cYN4UQJtPZitkB3BRjvLmn/fYYhjHGs0MI\n7wDeBRzctXkRcGGM8Y+9+PNk6ugj3szgQY1cMm3y1m1XXv9zvnzmBymVOti0aQsXXPEjVqxax4MP\nP813rplCoWtqxdwXFmdYeW1oXd5GU1P1drTv6g48cDz77z+OyZO/QF1dgWnTzsi6pJrjMd62lr0H\npbr/EMI7gQkxxkNDCEOBPwMzgetjjD8OIVwCnBJC+AFwPnAQsBmYHUK4M8a43ZXEC2m3dR90zFQb\n01N28zffw7h9RmZdRk3rU19HqdQn6zJqXrHYTqmUyxlfO01Dw5jULt8OOOLGXn3f/+V3p/VYWwih\nCPSLMa7r+nkZsBrYr+tq8FDgHDrHtJwSY/xY1+/dCPwixnj39vbtWSdJSkbKzaQxxhLw6tS+U4F7\ngGNijK/OeVsGjKSzO295t199dft2GYaSpGTspEEwIYR/oDMM3wPM7V7Bdn5lh4UZhpKkRLTslW6f\nIUAI4RhgGnBsjHFVCGFtCKF/jHEDMIrOcS2LeG2hGLq2P9LTfg1DSVIi5r+U7qT7EMIg4BvAu7sN\nhvkN8E/A7V3/vReYBXw3hDAYaAcOo3Nk6XYZhpKkZKTfTPphYBhwRwhbF0Y/mc7gOw1YAHw/xrgl\nhDAVuA8oAxfFGHtMasNQkpSMlLMwxngTcNM2Xjp6G+/9CfCT17tvw1CSlIy6bFeR6Q3DUJKUiJbR\n6Q+gSYthKElKxPyXV2ddQsUMQ0lSMqq3ldQwlCQlJOM7T/SGYShJSoZhKEnKu5bRb8i6hIoZhpKk\nRMxf5AAaSVLe2UwqScq7cvVmoWEoSUpGyygn3UuScs4+Q0mSXJtUkpR71ZuFhqEkKSGOJpUk5V3L\nKCfdS5Jybv7iNVmXUDHDUJKUjOptJTUMJUkJsc9QkpR7hqEkKe9a9hiYdQkVMwwlSYmYv2Rt1iVU\nzDCUJCXDZlJJUt551wpJUu61jNwt6xIqZhhKkhIxf6l9hpKkvLPPUJKUe9WbhYahJCkhXhlKkvKu\nZYST7rerWNyS9kfkXgcdrCttyLqMmtanYYDn8k5QKECx2J51GaqQA2h68NufnZb2R+Teg0te4qUl\n67Iuo6ZNGllPY13/rMuoefX1ZUolG6zSVFeX4s5tJpUk5V6dYShJyjn7DCVJuTdvmX2GkqS8s89Q\nkpR79hlKknKverPQMJQkJaNluANoJEk5N3959c53NgwlSclIc0J/ygxDSVIyHE0qScq7sqNJJUl5\n19LsABpJUs7Nb3UAjSQp7xxAI0nKPfsMJUl51zKsMfXPCCFMAO4CrokxfjuE0AB8H9gXWAOcGGNc\nEUKYDJwFdAA3xRhv7mm/hqEkKRHzX1mf6v5DCI3AdcDMbps/DSyPMX40hPAZ4PAQwkzgfOAgYDMw\nO4RwZ4yxbXv7ruIWXknSLqVQ6N1jxzYBxwOLum17PzAdIMZ4U4zx58DBwOwY46oY4wbgYeCwnnbs\nlaEkKRkpX17FGNuB9hBC980twHEhhCuAJcDpwAhgebf3LANG9rRvrwwlSYkoFwq9elSoAMQY45HA\nU8C523lPj7wylCQlYsxOGECzDUuB33X9fB9wEfBLOq8OXzUKeKSnnRiGkqREzGtLdwDNdvwKOBb4\nHjARiMAs4LshhMFAO539hWf1tBPDUJKUjJQX6g4hTASuorOfcEsI4UTgo8A3QwinAmuBk2OMG0II\nU+m8UiwDF8UYV/W0b8NQkpSM9AfQPA4cuY2XPrSN9/4E+Mnr3bdhKElKhrdwkiTl3ZihA7IuoWKG\noSQpEfNWbMi6hIoZhpKkZLhQtyQp73oxcT5zhqEkKRFjmvpnXULFDENJUiLmrbTPUJKUdzaTSpJy\nzwE0kqTcMwwlSXk3ZnC/rEuomGHYZfbsv3DOFy9j7Ni9ABg3roVz//W0jKuqDY/c+wcen/nHrc9f\nnLuAS2Zcxz23zmDWfQ/x1R9dm2F1tWfDho2cd961vPLKSjZv3sxpp/0zRxxxUNZl1ZzLL7+ROXP+\nChSYOnUKBxwQdvg7tW7eqo1Zl1CxisMwhDA4xrgyyWKyNvGtE7j66m3dF1K9ccixh3PIsYcD8Nyc\nyJO/f4wH7vgVQ5qHdq4nr0T97nePsv/++3LKKSeyaNEyPvOZ8wzDhM2ePYcFC15m+vRref75hZx/\n/tVMn+4/6vI6z3AGcFRShSgffv3Du5n8pU/Tp19f+g3ox7233ZV1STXn2GPfsfXnJUuWM3z4sAyr\nqU2zZj3BUUcdCsDYsXuxevVa1q5dx8CBmdzcdtdRq32GIYTTt/NSgc47B9eUF55/kTPP/CqrV61h\nypSPcOikA7MuqaYsjPMYPKyJNzQNyrqUXPjYx85h6dJX+Pa3z8+6lJrT2rqC8ePHbX0+ZMggWltX\nGIY1fGV4NvAbYPE2XmtIvpzs7LXXHkz5l49wzDFv56WXlnDqKf/KL++5iYaGmvpjZuqRe//A246e\nlHUZuXH77Vfy7LMvcO65V/HTn15HoYq/qHZ15bLt/VDbA2g+CHwL+HyMcVP3F0IIR6ZVVBaGDx/K\nsV39WnvuOZJhw4awdOkrjB49IuPKasfzcyInnP7RrMuoeU8//RxDhw5ixIhm9ttvH0qlEm1tqxg6\ndHDWpdWM5uYmWlvbtj5fvryN5uamDCvaNVTzAJoe70scY3wKeB+wZRsvfzGVijLyy1/8lltvnQF0\nNoG88spKhg8fmnFVtWPVKyvp278v9Q0OYE7b448/xfe/fyfQeS6vX7+RIUPekHFVtWXSpIncf/9D\nADzzzFyam5tobKzee/klpa6ud48s7fCbKca4fjvb/5R8Odk58p0H8eUvX8mDD85iy5Z2zjvvdJtI\nE7S6bSUDB7/2hTzj337I4nkvsWHdBq7/v1ew/yFv4ch/ek+GFdaOk046jvPP/xYnn/wlNm7czLRp\nU6jL+pumxhx44Hj2338ckyd/gbq6AtOmnZF1SbuEam6JL6Td1r1p899sTE/Zg0teolQyuNM0aeQg\nGuuqd0X+alFfX/ZcTllDw5jUIuv4/5jdq+/7ez7ytszi1DYrSVIi5q+u3j5Dw1CSlIhqbiY1DCVJ\niTAMJUm5ZxhKknKvZVDtTrqXJOl1WbDGATSSpJyzmVSSlHtVfNMKw1CSlBDDUJKUdy27OYBGkpRz\nC9Zu2vGbdlGGoSQpEQ6gkSTlXqGKb45iGEqSEtEy0D5DSVLOLVjnpHtJUs7ZZyhJyr0qzkLDUJKU\nDFegkSTl3t4OoJEk5d1CB9BIkvKuUMXtpIahJCkRjiaVJOWeYShJyr29Gh1AI0nKuRfXO4BGkpRz\nNpNKknKvigeTGoaSpGTsuRP6DEMIE4C7gGtijN8OIewJfA9oALYAH4sxLgkhTAbOAjqAm2KMN/e0\nX8NQkpSIl1LuMwwhNALXATO7bf4anWF3Rwjhs8DZIYSLgPOBg4DNwOwQwp0xxrbt7buKb8UoSdqV\nFOp693gdNgHHA4u6bTsd+GnXz8uBocDBwOwY46oY4wbgYeCwnnbslaEkKRGFlEfQxBjbgfYQQvdt\n6wBCCEXgs8DFwAg6g/FVy4CRPe3bK0NJUiIKhd49KtUVhLcBD8QYZ27jLTvcu1eGkqREjB6Q2aT7\n7wFzY4wXdT1fROfV4atGAY/0tAPDUJKUiJc37PxJ912jRjfHGC/otnkW8N0QwmCgnc7+wrN62o9h\nKElKRNqT7kMIE4GrgBZgSwjhRGB3YGMI4bddb3smxnh6CGEqcB9QBi6KMa7qad+ph2Gxvj3tj8i9\nQqHscU5boYO64qasq6h5hUI9xeKWrMtQhdIOwxjj48CRr/O9PwF+8nr3nXoYlkv90/6I3Dt61Cja\nS17kp6mjsJJN/nsjdX0bCnR4LqeqT4rDJl2BRpKUe6P7e9cKSVLOLdroXSskSTlXKJSzLqFihqEk\nKRHVvIqLYShJSsTofvYZSpJybtEm+wwlSTlXZ5+hJCnv7DOUJOWek+4lSbm3hwNoJEl5t8QBNJKk\nvCvgABpJUs7ZZyhJyr2Rfe0zlCTl3FL7DCVJeWczqSQp9wxDSVLuuQKNJCn3RjjpXpKUd0s3bci6\nhIoZhpKkRNhnKEnKPcNQkpR7dS7HJknKu+GuQCNJyrvlm12BRpKUc/YZSpJyzzCUJOXe7n3sM5Qk\n5VzrZifdS5JyzmZSSVLuGYaSpNzzrhWSpNwb5gAaSVLevbLFATSSpJyzz7BGXH75jcyZ81egwNSp\nUzjggJB1STXp6qtu4fE/PU2pvcSnPvUh3n30YVmXVDOem7uQsz9/JR/9+PH880eO5ckn/8Y3r76d\n+voiDQ0NfO2SMxjS9Iasy6wJnsf/U8EwrH6zZ89hwYKXmT79Wp5/fiHnn38106dfm3VZNefRR59k\n7nMLmD79KlauXM2HTvycXyIJ2bB+I1dc9j3edvCErdum/+AXXPz1zzJ69HBuvOHHzPjpTE799D9m\nWGVt8DzetpofQBNCKMQYy3+3bXSM8aV0ytr5Zs16gqOOOhSAsWP3YvXqtaxdu46BAxszrqy2TJw4\ngQkTOq+4d9utkQ0bNlIqlSgWixlXVv0a+jTwrevP5dZb7tq67YqrzgagXC6zbNkKDjzQ1o4keB5v\nW80OoAkh/CNwLTAghHAPcEaMcU3Xyz8Ajkq5vp2mtXUF48eP2/p8yJBBtLauMAwTViwWGTCg8wtj\nxoz7Ofzwt+b+CyQp9fVF6uv/57F8+KEn+MbltzJmzCiOf9/hGVRWezyPt62tigfQ7OiqdipwIDAc\neBi4P4QwqOu1Km4d3rFyuXpvUlkNHnjgj9w5437+ddq/ZF1KzTvs7W/hzp9fQ8uYPfjezXft+Bf0\nunke/7/qCr17ZFr7Dl4vxRjbYowdMcabgMuA+0IIw6CKb2m8Dc3NTbS2tm19vnx5G83NTRlWVLse\nfvhxvnPTHdzw7xez225eeafpgZmPAlAoFHjXuw/miT8/m3FFtcPz+H+q5jDcUZ/hQyGEXwAfijFu\niDHeFULYCMwEhqZf3s4zadJErr/+Nk466b0888xcmpubaGwckHVZNWfNmnVcdeUtfOe7X2fQoN2y\nLqfm3XjDjxk1anfCfi089Ze57N2yR9Yl1QTP420bWt8/6xIq1mMYxhi/FEI4EtjYbdt9IYQ/Ah9O\nubad6sADx7P//uOYPPkL1NUVmDbtjKxLqkn33vt7Vq5czTlfvGzrtksuPZuRI3fPsKra8MwzL3DN\nlbexaNFy6uuLzPz1LL5ywWlc+vWbKRbr6NuvD1/7uud1EjyPt21le/X2GRbS7hvbsmVeTTWn7oqK\nxU20l5wlk6aOwkpKHuPU9W1ooKPUN+syalqfhn1Ta5C84smZvfq+/9Kb35VZY6l/uyVJici63683\nDENJUiIMQ0lS7jWlOIAmhDCQzvntQ4C+wEXAEuAGOmc3zIkxVjzHxTCUJCViVSnVATSfBGKM8dwQ\nwh7AA8Bi4PMxxtkhhB+GEI6LMf6qkp1X81JykqRdSMrzDFt5bUrfEKANGBNjnN217W7g3RXXXukv\nSpLUXaFQ7tWjJzHG/wT2CiE8B/weOAdY0e0ty4CRldZuGEqSElHs5aMnIYSPAQtjjPvSuS727X/3\nll4N37HPUJKUiMHprkBzGHAfQIzxyRBCf6Ch2+ujgEWV7twwlCQlYnW6A2ieAw4GfhpC2BtYA8wP\nIbw9xvgQcAJwXaU7NwwlSYlIud/tRuCWEMLv6MyuKXROrbgxhFAHzIox/qbSnRuGkqRE1O1gEExv\nxBjXAidt46VEbtJpGEqSEjGoVu9aIUnS67U23T7DVBmGkqREuDapJCn3DENJUu4ZhpKk3Nut2C/r\nEipmGEqSErG+wwE0kqScq+bFrg1DSVIiCvYZSpLyrmgYSpLybmDRFWgkSTm3vmN91iVUzDCUJCXC\neYaSpNwzDCVJuTegbkDWJVTMMJQkJWJj2T5DSVLOObVCkpR7ad7pPm2GoSQpES7HJknKvf4OoJEk\n5d0mB9BIkvLOATSSpNwrOIBGkpR3rkAjScq9fgUH0GxXsdie9kfkXqFQpt7jnKot5bLn8k5QKNRT\nLG7OugxVaDMOoNmuUsmLz7QVix7ntDUU62jv8BinrdSxllKpmmer7fr690lv39X8f86/3ZKkRBTs\nM5Qk5V0f7DOUJOXcFvsMJUl5V8WtpIahJCkZzjOUJOVeAVegkSTlXIMDaCRJeddecACNJCnnqrjL\n0DCUJCXDSfeSpNyzz1CSlHtVfGFoGEqSklFyBRpJUt5Vc59hNd9xQ5KkRHhlKElKRH3ZATSSpJzr\ncNK9JCnvqrnP0DCUJCWiirPQMJQkJaNQ8K4VkqScK+6EATQhhP7AU8BXgZnAbUARWAx8PMa4qZL9\nOrVCkpSIjsL6Xj1ep/OAtq6fLwaujzEeDjwHnFJp7YahJCkRhULvHjsSQtgPGA/8smvTkcDPu36+\nG3h3pbUbhpKkRNT18vE6XAWc3e15Y7dm0WXAyEprt89QkpSIYop3rQghfAL4Y4xxXghhW2/p1WBW\nw1CSlIiUJ92/F9gnhPA+YDSwCVgbQugfY9wAjAIWVbpzw1CSlIg05xnGGD/86s8hhAuB+cAk4J+A\n27v+e2+l+7fPUJKUiLQH0GzDBcDJIYQ/AE3A9yut3StDSVIidtYKNDHGC7s9PTqJfRqGkqRE7IxJ\n92kxDCVJiSjXedcKSVLOuVC3JCn3XKhbkpR7XhlKknKvUG7MuoSKGYbdXH75jcyZ81egwNSpUzjg\ngG0u+aNe8jinb+7c+XzuzIv4+Cf+kY9+9ANZl1NzOjo6+NrF/85zzy2koaGe874yhTH7jM66rOzV\nrcu6gor9f0+6DyEMS6OQrM2ePYcFC15m+vRrufjiL3DZZTdkXVJN8jinb/36jVx6yQ0cfMhbsi6l\nZv32wUdZu3Y9P7j9Mi68+LNcfdWtWZe0Syj08pGlHq8MQwjvBa4GXgTOAqYD9SGERuD0GOM96Ze4\nc8ya9QRHHXUoAGPH7sXq1WtZu3YdAwdW72X/rsjjnL4+fRr4txsu5pabf5x1KTVrwYLFTDhgHAB7\n7jmSxYuWUyqVKBaLGVeWrWpe0mxHtZ9H5+z+C4FfAJ+IMe4PHNy1rWa0tq6gqWnw1udDhgyitXVF\nhhXVJo9z+urri/Tr1zfrMmrauHF78V8P/5lSqcT8eS/z0stLWbliTdZlZa/c2LtHhnbUZ7gpxrgQ\nWBhCeDnG+CRAjHFpCGFj+uVlp1yu3iHC1cTjrGr09sMn8sSfn+WUT57HG9+4N/uMGU0Zz+Vq7jPc\nURguDSGcE2O8MsZ4GEAIYTTwRTqbTmtGc3MTra1tW58vX95Gc3NThhXVJo+zasUZn5u89ef3HTeF\npqZBGVazayhk3vNXuR01k34SWPh323YHFgCnplFQViZNmsj99z8EwDPPzKW5uYnGxupdZ29X5XFW\nLYhxHhd85ToAHn7oT+z3pn2oq6vmHrOkVO8QmkLazVRbtsyrmraDa665hcce+wt1dQWmTTuD/fbb\nJ+uSXpdisZ1SqXpmyVTjcS4Wt9BeJcf46afncuU3vsOiRUupr69n992Hcu03v8KgQbtlXdqO1a2t\ninO5o6ODC77ybV544UX69unDJZd/gREjqmOgff8+41NLnRWb7u3V9/2QvsdmloiGYQ2otjCsRtUU\nhlWtSsKwmqUZhm3r/9Cr7/umAYdnFoaedZKkRBSK3rVCkpRz1TyAxjCUJCXEMJQk5VyhUL0jag1D\nSVIiyqXqnSZlGEqSElEobsi6hIoZhpKkRDiARpKUe4ahJCn37DOUJOVeoVi9NzMyDCVJiSgUbCaV\nJOWeYShJyjkH0EiScq+j1L93O2hIpo5KGIaSpETUFTdlXULFDENJUiKqt5HUMJQkJcTRpJIk4V0r\nJEk5Vy71690OMkwkw1CSlAgH0EiSVMVDaAxDSVIiHEAjScq9Uqlv73ZQTKaOShiGkqREFIubsy6h\nYoahJCkRBadWSJJkn6EkKee8a4UkKfc6Sn16twMH0EiSql2xuCXrEipmGEqSEuIAGklSztlnKEmS\nK9BIkvKuVGro1e8Xd9DKGkK4BjgEKAOfjzHO7tUHdmMYSpISUSy2p7bvEMIRwLgY46EhhDcBtwCH\nJrX/6u3tlCTtUgrU9eqxA+8CfgYQY/wrMCSE8IakavfKUJKUiN42k9b1nIcjgMe7PV/etW11rz60\nS+ph2NAwpnp7VKvIDk4iJaCPx3jnyHDitXpnJ3/fJ/pZ/vWWJFWDRXReCb5qD2BxUjs3DCVJ1eB+\n4ESAEML/BhbFGNcktfNCuVxOal+SJKUmhHAZ8A6gA/hsjPHJpPZtGEqScs9mUklS7hmGkqTcc55h\nN2ku9aPXhBAmAHcB18QYv511PbUohHAFcDidf8cvjTHOyLikmhJCGADcCgwH+gFfjTH+ItOi1Cte\nGXbpvtQPcCrwrYxLqkkhhEbgOmBm1rXUqhDCO4EJXefyscC1GZdUi94PPBZjPAI4Cbg643rUS4bh\na1Jd6kdbbQKOp3POkNLxe+BDXT+vBBpDCE5lT1CM8Ucxxiu6nu4JvJRlPeo9m0lfk+pSP+oUY2wH\n2kMIWZdSs2KMJWBd19NTgXu6tilhIYT/AkYD78u6FvWOV4bb5zJyqmohhH+gMwzPyLqWWhVjnAR8\nALg9hOB3RhUzDF+T6lI/0s4UQjgGmAYcF2NclXU9tSaEMDGEsCdAjPEJOlvZmrOtSr1hGL4m1aV+\npJ0lhDAI+AbwvhhjW9b11Kh3AF8ECCEMBwYCrZlWpF5xBZpu0lzqR51CCBOBq4AWYAvwMnCCX9rJ\nCSF8BrgQ+Fu3zZ+IMS7MpqLaE0LoD9xM5+CZ/sBFMca7s61KvWEYSpJyz2ZSSVLuGYaSpNwzDCVJ\nuWcYSpJyzzCUJOWeYShJyj3DUJKUe4ahJCn3/hu3Bamcql57zwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5061f6cdd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AqiXdFuf4wxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Gaussian Process"
      ]
    },
    {
      "metadata": {
        "id": "t2fUJPuF4t_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "collapsed": true,
        "outputId": "ebda0818-33b4-4254-d824-db86daf77e9d"
      },
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Dense(256, input_dim=input_dim, activation='tanh',kernel_initializer='glorot_uniform'))\n",
        "model_3.add(Dropout(0.0))\n",
        "model_3.add(Dense(256, activation='tanh',kernel_initializer='glorot_uniform'))\n",
        "model_3.add(Dropout(0.0))\n",
        "model_3.add(Dense(4, activation='softmax',kernel_initializer='glorot_uniform'))\n",
        "model_3.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='Nadam',\n",
        "        metrics=['accuracy'])\n",
        "model_3_history=model_3.fit(X_train,y_train, batch_size=16,epochs=100,validation_data=(X_test,y_test),verbose=2 )"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1382 samples, validate on 346 samples\n",
            "Epoch 1/100\n",
            " - 1s - loss: 0.6958 - acc: 0.7004 - val_loss: 0.7296 - val_acc: 0.7023\n",
            "Epoch 2/100\n",
            " - 0s - loss: 0.5303 - acc: 0.7771 - val_loss: 1.1988 - val_acc: 0.5173\n",
            "Epoch 3/100\n",
            " - 0s - loss: 0.4546 - acc: 0.8068 - val_loss: 0.3706 - val_acc: 0.8237\n",
            "Epoch 4/100\n",
            " - 0s - loss: 0.3649 - acc: 0.8357 - val_loss: 0.2820 - val_acc: 0.8931\n",
            "Epoch 5/100\n",
            " - 0s - loss: 0.3091 - acc: 0.8842 - val_loss: 0.2624 - val_acc: 0.8931\n",
            "Epoch 6/100\n",
            " - 0s - loss: 0.2793 - acc: 0.8864 - val_loss: 0.2462 - val_acc: 0.9017\n",
            "Epoch 7/100\n",
            " - 0s - loss: 0.2636 - acc: 0.8900 - val_loss: 0.3697 - val_acc: 0.8584\n",
            "Epoch 8/100\n",
            " - 0s - loss: 0.2464 - acc: 0.9030 - val_loss: 0.3241 - val_acc: 0.8728\n",
            "Epoch 9/100\n",
            " - 0s - loss: 0.2319 - acc: 0.9074 - val_loss: 0.2060 - val_acc: 0.9220\n",
            "Epoch 10/100\n",
            " - 0s - loss: 0.2101 - acc: 0.9204 - val_loss: 0.3590 - val_acc: 0.8266\n",
            "Epoch 11/100\n",
            " - 0s - loss: 0.1997 - acc: 0.9247 - val_loss: 0.1775 - val_acc: 0.9306\n",
            "Epoch 12/100\n",
            " - 0s - loss: 0.1922 - acc: 0.9168 - val_loss: 0.3414 - val_acc: 0.8353\n",
            "Epoch 13/100\n",
            " - 0s - loss: 0.1763 - acc: 0.9269 - val_loss: 0.1767 - val_acc: 0.9335\n",
            "Epoch 14/100\n",
            " - 0s - loss: 0.1720 - acc: 0.9334 - val_loss: 0.1657 - val_acc: 0.9335\n",
            "Epoch 15/100\n",
            " - 0s - loss: 0.1473 - acc: 0.9392 - val_loss: 0.1703 - val_acc: 0.9249\n",
            "Epoch 16/100\n",
            " - 0s - loss: 0.1559 - acc: 0.9342 - val_loss: 0.1737 - val_acc: 0.9133\n",
            "Epoch 17/100\n",
            " - 0s - loss: 0.1344 - acc: 0.9486 - val_loss: 0.1422 - val_acc: 0.9480\n",
            "Epoch 18/100\n",
            " - 0s - loss: 0.1303 - acc: 0.9493 - val_loss: 0.2376 - val_acc: 0.8815\n",
            "Epoch 19/100\n",
            " - 0s - loss: 0.1184 - acc: 0.9501 - val_loss: 0.1182 - val_acc: 0.9509\n",
            "Epoch 20/100\n",
            " - 0s - loss: 0.1184 - acc: 0.9515 - val_loss: 0.1224 - val_acc: 0.9509\n",
            "Epoch 21/100\n",
            " - 0s - loss: 0.1103 - acc: 0.9544 - val_loss: 0.1905 - val_acc: 0.9191\n",
            "Epoch 22/100\n",
            " - 0s - loss: 0.1103 - acc: 0.9609 - val_loss: 0.1020 - val_acc: 0.9711\n",
            "Epoch 23/100\n",
            " - 0s - loss: 0.0922 - acc: 0.9653 - val_loss: 0.1301 - val_acc: 0.9480\n",
            "Epoch 24/100\n",
            " - 0s - loss: 0.0849 - acc: 0.9703 - val_loss: 0.2178 - val_acc: 0.9133\n",
            "Epoch 25/100\n",
            " - 0s - loss: 0.0806 - acc: 0.9696 - val_loss: 0.1061 - val_acc: 0.9682\n",
            "Epoch 26/100\n",
            " - 0s - loss: 0.0721 - acc: 0.9776 - val_loss: 0.0951 - val_acc: 0.9682\n",
            "Epoch 27/100\n",
            " - 0s - loss: 0.0668 - acc: 0.9740 - val_loss: 0.1140 - val_acc: 0.9451\n",
            "Epoch 28/100\n",
            " - 0s - loss: 0.0651 - acc: 0.9805 - val_loss: 0.1061 - val_acc: 0.9538\n",
            "Epoch 29/100\n",
            " - 0s - loss: 0.0612 - acc: 0.9790 - val_loss: 0.0933 - val_acc: 0.9682\n",
            "Epoch 30/100\n",
            " - 0s - loss: 0.0535 - acc: 0.9826 - val_loss: 0.0729 - val_acc: 0.9827\n",
            "Epoch 31/100\n",
            " - 0s - loss: 0.0425 - acc: 0.9899 - val_loss: 0.0700 - val_acc: 0.9769\n",
            "Epoch 32/100\n",
            " - 0s - loss: 0.0514 - acc: 0.9855 - val_loss: 0.0980 - val_acc: 0.9595\n",
            "Epoch 33/100\n",
            " - 0s - loss: 0.0606 - acc: 0.9776 - val_loss: 0.0738 - val_acc: 0.9740\n",
            "Epoch 34/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 0s - loss: 0.0362 - acc: 0.9884 - val_loss: 0.0708 - val_acc: 0.9711\n",
            "Epoch 35/100\n",
            " - 0s - loss: 0.0306 - acc: 0.9928 - val_loss: 0.0580 - val_acc: 0.9884\n",
            "Epoch 36/100\n",
            " - 0s - loss: 0.0313 - acc: 0.9920 - val_loss: 0.1094 - val_acc: 0.9653\n",
            "Epoch 37/100\n",
            " - 0s - loss: 0.0324 - acc: 0.9906 - val_loss: 0.1477 - val_acc: 0.9335\n",
            "Epoch 38/100\n",
            " - 0s - loss: 0.0318 - acc: 0.9920 - val_loss: 0.0738 - val_acc: 0.9711\n",
            "Epoch 39/100\n",
            " - 0s - loss: 0.0213 - acc: 0.9964 - val_loss: 0.0580 - val_acc: 0.9855\n",
            "Epoch 40/100\n",
            " - 0s - loss: 0.0345 - acc: 0.9877 - val_loss: 0.0804 - val_acc: 0.9769\n",
            "Epoch 41/100\n",
            " - 0s - loss: 0.0256 - acc: 0.9971 - val_loss: 0.0510 - val_acc: 0.9798\n",
            "Epoch 42/100\n",
            " - 0s - loss: 0.0320 - acc: 0.9928 - val_loss: 0.0573 - val_acc: 0.9798\n",
            "Epoch 43/100\n",
            " - 0s - loss: 0.0259 - acc: 0.9935 - val_loss: 0.0539 - val_acc: 0.9884\n",
            "Epoch 44/100\n",
            " - 0s - loss: 0.0193 - acc: 0.9957 - val_loss: 0.0879 - val_acc: 0.9624\n",
            "Epoch 45/100\n",
            " - 0s - loss: 0.0251 - acc: 0.9920 - val_loss: 0.0614 - val_acc: 0.9855\n",
            "Epoch 46/100\n",
            " - 0s - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0408 - val_acc: 0.9884\n",
            "Epoch 47/100\n",
            " - 0s - loss: 0.0124 - acc: 0.9986 - val_loss: 0.0311 - val_acc: 0.9884\n",
            "Epoch 48/100\n",
            " - 0s - loss: 0.0113 - acc: 0.9986 - val_loss: 0.0618 - val_acc: 0.9711\n",
            "Epoch 49/100\n",
            " - 0s - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0382 - val_acc: 0.9855\n",
            "Epoch 50/100\n",
            " - 0s - loss: 0.0212 - acc: 0.9920 - val_loss: 0.0573 - val_acc: 0.9827\n",
            "Epoch 51/100\n",
            " - 0s - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0505 - val_acc: 0.9798\n",
            "Epoch 52/100\n",
            " - 0s - loss: 0.0089 - acc: 0.9993 - val_loss: 0.0234 - val_acc: 0.9971\n",
            "Epoch 53/100\n",
            " - 0s - loss: 0.0087 - acc: 0.9993 - val_loss: 0.0363 - val_acc: 0.9913\n",
            "Epoch 54/100\n",
            " - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9942\n",
            "Epoch 55/100\n",
            " - 0s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 0.9942\n",
            "Epoch 56/100\n",
            " - 0s - loss: 0.0082 - acc: 0.9993 - val_loss: 0.0324 - val_acc: 0.9913\n",
            "Epoch 57/100\n",
            " - 0s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9884\n",
            "Epoch 58/100\n",
            " - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9942\n",
            "Epoch 59/100\n",
            " - 0s - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0290 - val_acc: 0.9913\n",
            "Epoch 60/100\n",
            " - 0s - loss: 0.1958 - acc: 0.9436 - val_loss: 0.1553 - val_acc: 0.9220\n",
            "Epoch 61/100\n",
            " - 0s - loss: 0.0843 - acc: 0.9682 - val_loss: 0.0849 - val_acc: 0.9595\n",
            "Epoch 62/100\n",
            " - 0s - loss: 0.0327 - acc: 0.9884 - val_loss: 0.0411 - val_acc: 0.9855\n",
            "Epoch 63/100\n",
            " - 0s - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0273 - val_acc: 0.9913\n",
            "Epoch 64/100\n",
            " - 0s - loss: 0.0071 - acc: 0.9993 - val_loss: 0.0215 - val_acc: 0.9913\n",
            "Epoch 65/100\n",
            " - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9971\n",
            "Epoch 66/100\n",
            " - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9942\n",
            "Epoch 67/100\n",
            " - 0s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 68/100\n",
            " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9942\n",
            "Epoch 69/100\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9942\n",
            "Epoch 70/100\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9942\n",
            "Epoch 71/100\n",
            " - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9942\n",
            "Epoch 72/100\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9971\n",
            "Epoch 73/100\n",
            " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9942\n",
            "Epoch 74/100\n",
            " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9971\n",
            "Epoch 75/100\n",
            " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9971\n",
            "Epoch 76/100\n",
            " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9942\n",
            "Epoch 77/100\n",
            " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9971\n",
            "Epoch 78/100\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9942\n",
            "Epoch 79/100\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9971\n",
            "Epoch 80/100\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9971\n",
            "Epoch 81/100\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9971\n",
            "Epoch 82/100\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9971\n",
            "Epoch 83/100\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9971\n",
            "Epoch 84/100\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9971\n",
            "Epoch 85/100\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9971\n",
            "Epoch 86/100\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9971\n",
            "Epoch 87/100\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9942\n",
            "Epoch 88/100\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9971\n",
            "Epoch 89/100\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9971\n",
            "Epoch 90/100\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9971\n",
            "Epoch 91/100\n",
            " - 0s - loss: 9.7677e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9971\n",
            "Epoch 92/100\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9971\n",
            "Epoch 93/100\n",
            " - 0s - loss: 0.1939 - acc: 0.9660 - val_loss: 0.5182 - val_acc: 0.8613\n",
            "Epoch 94/100\n",
            " - 0s - loss: 0.1471 - acc: 0.9436 - val_loss: 0.0885 - val_acc: 0.9566\n",
            "Epoch 95/100\n",
            " - 0s - loss: 0.0316 - acc: 0.9913 - val_loss: 0.0535 - val_acc: 0.9913\n",
            "Epoch 96/100\n",
            " - 0s - loss: 0.0216 - acc: 0.9935 - val_loss: 0.0330 - val_acc: 0.9913\n",
            "Epoch 97/100\n",
            " - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9971\n",
            "Epoch 98/100\n",
            " - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9942\n",
            "Epoch 99/100\n",
            " - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9971\n",
            "Epoch 100/100\n",
            " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AUKt4Mnv5Tde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "02230c81-e47b-4976-a012-bcbc385a3f8b"
      },
      "cell_type": "code",
      "source": [
        "model_3_train_score = model_3.evaluate(X_train,y_train,verbose=0)\n",
        "model_3_score = model_3.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Train loss: \",model_3_train_score[0])\n",
        "print(\"Test loss: \",model_3_score[0])\n",
        "print(\"Train accuracy: %.4f%%\"% (model_3_train_score[1]*100))\n",
        "print(\"Test accuracy: %.4f%%\"%(model_3_score[1]*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train loss: ', 0.0025419136002614645)\n",
            "('Test loss: ', 0.021032969774193847)\n",
            "Train accuracy: 100.0000%\n",
            "Test accuracy: 99.4220%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w55ON96U5wbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "0bc2d748-a99a-4a3f-f015-6dc4d45080b0"
      },
      "cell_type": "code",
      "source": [
        "y_pred_class = model_3.predict_classes(X_test,verbose=0)\n",
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "plot_confusion_matrix(model_3, X_test, y_test_class)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       1.00      1.00      1.00       240\n",
            "          1       0.99      0.99      0.99        79\n",
            "          2       0.94      1.00      0.97        17\n",
            "          3       1.00      1.00      1.00        10\n",
            "\n",
            "avg / total       0.99      0.99      0.99       346\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFlCAYAAACXw4MtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlHuGoSQp9/4/OJFWrlNLh+IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5061f33f10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-w-DSZv256ft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. TPE Search"
      ]
    },
    {
      "metadata": {
        "id": "0sgRhGWx5poR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "collapsed": true,
        "outputId": "2f38183b-4146-4274-a345-45f4cc527ef4"
      },
      "cell_type": "code",
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Dense(64, input_dim=input_dim, activation='relu',kernel_initializer='he_normal'))\n",
        "model_4.add(Dropout(0.0))\n",
        "model_4.add(Dense(64, activation='relu',kernel_initializer='he_uniform'))\n",
        "model_4.add(Dropout(0.1))\n",
        "model_4.add(Dense(4, activation='softmax',kernel_initializer='lecun_uniform'))\n",
        "model_4.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='Nadam',\n",
        "        metrics=['accuracy'])\n",
        "model_4_history=model_4.fit(X_train,y_train, batch_size=16,epochs=100,validation_data=(X_test,y_test),verbose=2 )"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1382 samples, validate on 346 samples\n",
            "Epoch 1/100\n",
            " - 1s - loss: 0.8224 - acc: 0.6881 - val_loss: 0.5271 - val_acc: 0.7746\n",
            "Epoch 2/100\n",
            " - 0s - loss: 0.5083 - acc: 0.7887 - val_loss: 0.4130 - val_acc: 0.8382\n",
            "Epoch 3/100\n",
            " - 0s - loss: 0.4229 - acc: 0.8205 - val_loss: 0.3691 - val_acc: 0.8295\n",
            "Epoch 4/100\n",
            " - 0s - loss: 0.3624 - acc: 0.8553 - val_loss: 0.3106 - val_acc: 0.8728\n",
            "Epoch 5/100\n",
            " - 0s - loss: 0.3098 - acc: 0.8712 - val_loss: 0.2989 - val_acc: 0.8844\n",
            "Epoch 6/100\n",
            " - 0s - loss: 0.2938 - acc: 0.8849 - val_loss: 0.2878 - val_acc: 0.8844\n",
            "Epoch 7/100\n",
            " - 0s - loss: 0.2825 - acc: 0.8755 - val_loss: 0.2512 - val_acc: 0.8931\n",
            "Epoch 8/100\n",
            " - 0s - loss: 0.2610 - acc: 0.8915 - val_loss: 0.4853 - val_acc: 0.7717\n",
            "Epoch 9/100\n",
            " - 0s - loss: 0.2539 - acc: 0.8973 - val_loss: 0.2243 - val_acc: 0.9046\n",
            "Epoch 10/100\n",
            " - 0s - loss: 0.2467 - acc: 0.9009 - val_loss: 0.2247 - val_acc: 0.9133\n",
            "Epoch 11/100\n",
            " - 0s - loss: 0.2266 - acc: 0.9110 - val_loss: 0.2545 - val_acc: 0.8902\n",
            "Epoch 12/100\n",
            " - 0s - loss: 0.2170 - acc: 0.9074 - val_loss: 0.2070 - val_acc: 0.9133\n",
            "Epoch 13/100\n",
            " - 0s - loss: 0.2143 - acc: 0.9088 - val_loss: 0.2198 - val_acc: 0.9104\n",
            "Epoch 14/100\n",
            " - 0s - loss: 0.2029 - acc: 0.9182 - val_loss: 0.2248 - val_acc: 0.9017\n",
            "Epoch 15/100\n",
            " - 0s - loss: 0.1961 - acc: 0.9284 - val_loss: 0.2376 - val_acc: 0.9075\n",
            "Epoch 16/100\n",
            " - 0s - loss: 0.1822 - acc: 0.9269 - val_loss: 0.1894 - val_acc: 0.9133\n",
            "Epoch 17/100\n",
            " - 0s - loss: 0.1957 - acc: 0.9190 - val_loss: 0.2845 - val_acc: 0.8873\n",
            "Epoch 18/100\n",
            " - 0s - loss: 0.1820 - acc: 0.9211 - val_loss: 0.2350 - val_acc: 0.8931\n",
            "Epoch 19/100\n",
            " - 0s - loss: 0.1785 - acc: 0.9233 - val_loss: 0.2167 - val_acc: 0.9017\n",
            "Epoch 20/100\n",
            " - 0s - loss: 0.1704 - acc: 0.9320 - val_loss: 0.1906 - val_acc: 0.9277\n",
            "Epoch 21/100\n",
            " - 0s - loss: 0.1608 - acc: 0.9392 - val_loss: 0.2036 - val_acc: 0.9335\n",
            "Epoch 22/100\n",
            " - 0s - loss: 0.1599 - acc: 0.9342 - val_loss: 0.1750 - val_acc: 0.9162\n",
            "Epoch 23/100\n",
            " - 0s - loss: 0.1595 - acc: 0.9421 - val_loss: 0.1788 - val_acc: 0.9277\n",
            "Epoch 24/100\n",
            " - 0s - loss: 0.1570 - acc: 0.9342 - val_loss: 0.1745 - val_acc: 0.9249\n",
            "Epoch 25/100\n",
            " - 0s - loss: 0.1593 - acc: 0.9392 - val_loss: 0.1704 - val_acc: 0.9306\n",
            "Epoch 26/100\n",
            " - 0s - loss: 0.1383 - acc: 0.9457 - val_loss: 0.1811 - val_acc: 0.9277\n",
            "Epoch 27/100\n",
            " - 0s - loss: 0.1458 - acc: 0.9385 - val_loss: 0.2555 - val_acc: 0.9046\n",
            "Epoch 28/100\n",
            " - 0s - loss: 0.1515 - acc: 0.9385 - val_loss: 0.1856 - val_acc: 0.9306\n",
            "Epoch 29/100\n",
            " - 0s - loss: 0.1377 - acc: 0.9457 - val_loss: 0.1673 - val_acc: 0.9364\n",
            "Epoch 30/100\n",
            " - 0s - loss: 0.1474 - acc: 0.9436 - val_loss: 0.1507 - val_acc: 0.9335\n",
            "Epoch 31/100\n",
            " - 0s - loss: 0.1335 - acc: 0.9465 - val_loss: 0.1507 - val_acc: 0.9335\n",
            "Epoch 32/100\n",
            " - 0s - loss: 0.1285 - acc: 0.9508 - val_loss: 0.1813 - val_acc: 0.9220\n",
            "Epoch 33/100\n",
            " - 0s - loss: 0.1294 - acc: 0.9522 - val_loss: 0.1786 - val_acc: 0.9249\n",
            "Epoch 34/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 0s - loss: 0.1369 - acc: 0.9450 - val_loss: 0.1916 - val_acc: 0.9075\n",
            "Epoch 35/100\n",
            " - 0s - loss: 0.1333 - acc: 0.9443 - val_loss: 0.1481 - val_acc: 0.9364\n",
            "Epoch 36/100\n",
            " - 0s - loss: 0.1284 - acc: 0.9493 - val_loss: 0.1574 - val_acc: 0.9335\n",
            "Epoch 37/100\n",
            " - 0s - loss: 0.1190 - acc: 0.9544 - val_loss: 0.1469 - val_acc: 0.9480\n",
            "Epoch 38/100\n",
            " - 0s - loss: 0.1142 - acc: 0.9595 - val_loss: 0.1970 - val_acc: 0.9191\n",
            "Epoch 39/100\n",
            " - 0s - loss: 0.1322 - acc: 0.9414 - val_loss: 0.1588 - val_acc: 0.9393\n",
            "Epoch 40/100\n",
            " - 0s - loss: 0.1162 - acc: 0.9493 - val_loss: 0.1552 - val_acc: 0.9306\n",
            "Epoch 41/100\n",
            " - 0s - loss: 0.1185 - acc: 0.9537 - val_loss: 0.1341 - val_acc: 0.9509\n",
            "Epoch 42/100\n",
            " - 0s - loss: 0.1164 - acc: 0.9530 - val_loss: 0.1584 - val_acc: 0.9364\n",
            "Epoch 43/100\n",
            " - 0s - loss: 0.1021 - acc: 0.9609 - val_loss: 0.1427 - val_acc: 0.9509\n",
            "Epoch 44/100\n",
            " - 0s - loss: 0.1092 - acc: 0.9537 - val_loss: 0.1904 - val_acc: 0.9249\n",
            "Epoch 45/100\n",
            " - 0s - loss: 0.1110 - acc: 0.9515 - val_loss: 0.1494 - val_acc: 0.9422\n",
            "Epoch 46/100\n",
            " - 0s - loss: 0.1166 - acc: 0.9522 - val_loss: 0.1218 - val_acc: 0.9538\n",
            "Epoch 47/100\n",
            " - 0s - loss: 0.1108 - acc: 0.9580 - val_loss: 0.1213 - val_acc: 0.9566\n",
            "Epoch 48/100\n",
            " - 0s - loss: 0.0940 - acc: 0.9696 - val_loss: 0.1183 - val_acc: 0.9566\n",
            "Epoch 49/100\n",
            " - 0s - loss: 0.1078 - acc: 0.9493 - val_loss: 0.1465 - val_acc: 0.9422\n",
            "Epoch 50/100\n",
            " - 0s - loss: 0.0936 - acc: 0.9645 - val_loss: 0.1465 - val_acc: 0.9393\n",
            "Epoch 51/100\n",
            " - 0s - loss: 0.1144 - acc: 0.9493 - val_loss: 0.1364 - val_acc: 0.9538\n",
            "Epoch 52/100\n",
            " - 0s - loss: 0.0936 - acc: 0.9602 - val_loss: 0.1089 - val_acc: 0.9711\n",
            "Epoch 53/100\n",
            " - 0s - loss: 0.1004 - acc: 0.9559 - val_loss: 0.1252 - val_acc: 0.9624\n",
            "Epoch 54/100\n",
            " - 0s - loss: 0.0958 - acc: 0.9616 - val_loss: 0.1286 - val_acc: 0.9566\n",
            "Epoch 55/100\n",
            " - 0s - loss: 0.0738 - acc: 0.9740 - val_loss: 0.1556 - val_acc: 0.9335\n",
            "Epoch 56/100\n",
            " - 0s - loss: 0.0867 - acc: 0.9660 - val_loss: 0.1147 - val_acc: 0.9566\n",
            "Epoch 57/100\n",
            " - 0s - loss: 0.0849 - acc: 0.9638 - val_loss: 0.1143 - val_acc: 0.9538\n",
            "Epoch 58/100\n",
            " - 0s - loss: 0.0825 - acc: 0.9631 - val_loss: 0.1085 - val_acc: 0.9566\n",
            "Epoch 59/100\n",
            " - 0s - loss: 0.0917 - acc: 0.9653 - val_loss: 0.1216 - val_acc: 0.9422\n",
            "Epoch 60/100\n",
            " - 0s - loss: 0.0822 - acc: 0.9638 - val_loss: 0.1093 - val_acc: 0.9538\n",
            "Epoch 61/100\n",
            " - 0s - loss: 0.0767 - acc: 0.9725 - val_loss: 0.1134 - val_acc: 0.9480\n",
            "Epoch 62/100\n",
            " - 0s - loss: 0.0740 - acc: 0.9660 - val_loss: 0.1001 - val_acc: 0.9711\n",
            "Epoch 63/100\n",
            " - 0s - loss: 0.0806 - acc: 0.9638 - val_loss: 0.1004 - val_acc: 0.9566\n",
            "Epoch 64/100\n",
            " - 0s - loss: 0.0788 - acc: 0.9682 - val_loss: 0.1036 - val_acc: 0.9711\n",
            "Epoch 65/100\n",
            " - 0s - loss: 0.0884 - acc: 0.9624 - val_loss: 0.1218 - val_acc: 0.9595\n",
            "Epoch 66/100\n",
            " - 0s - loss: 0.0861 - acc: 0.9667 - val_loss: 0.1269 - val_acc: 0.9480\n",
            "Epoch 67/100\n",
            " - 0s - loss: 0.0900 - acc: 0.9580 - val_loss: 0.1097 - val_acc: 0.9653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 68/100\n",
            " - 0s - loss: 0.0778 - acc: 0.9660 - val_loss: 0.0892 - val_acc: 0.9769\n",
            "Epoch 69/100\n",
            " - 0s - loss: 0.0734 - acc: 0.9645 - val_loss: 0.0975 - val_acc: 0.9595\n",
            "Epoch 70/100\n",
            " - 0s - loss: 0.0675 - acc: 0.9711 - val_loss: 0.0937 - val_acc: 0.9711\n",
            "Epoch 71/100\n",
            " - 0s - loss: 0.0781 - acc: 0.9682 - val_loss: 0.1386 - val_acc: 0.9451\n",
            "Epoch 72/100\n",
            " - 0s - loss: 0.0953 - acc: 0.9544 - val_loss: 0.1074 - val_acc: 0.9566\n",
            "Epoch 73/100\n",
            " - 0s - loss: 0.0717 - acc: 0.9696 - val_loss: 0.1027 - val_acc: 0.9595\n",
            "Epoch 74/100\n",
            " - 0s - loss: 0.0705 - acc: 0.9711 - val_loss: 0.1053 - val_acc: 0.9624\n",
            "Epoch 75/100\n",
            " - 0s - loss: 0.0712 - acc: 0.9711 - val_loss: 0.1199 - val_acc: 0.9566\n",
            "Epoch 76/100\n",
            " - 0s - loss: 0.0649 - acc: 0.9725 - val_loss: 0.0839 - val_acc: 0.9740\n",
            "Epoch 77/100\n",
            " - 0s - loss: 0.0743 - acc: 0.9682 - val_loss: 0.0869 - val_acc: 0.9653\n",
            "Epoch 78/100\n",
            " - 0s - loss: 0.0620 - acc: 0.9732 - val_loss: 0.0784 - val_acc: 0.9740\n",
            "Epoch 79/100\n",
            " - 0s - loss: 0.0709 - acc: 0.9667 - val_loss: 0.0826 - val_acc: 0.9769\n",
            "Epoch 80/100\n",
            " - 0s - loss: 0.0707 - acc: 0.9703 - val_loss: 0.0989 - val_acc: 0.9653\n",
            "Epoch 81/100\n",
            " - 0s - loss: 0.0602 - acc: 0.9754 - val_loss: 0.0903 - val_acc: 0.9682\n",
            "Epoch 82/100\n",
            " - 0s - loss: 0.0595 - acc: 0.9747 - val_loss: 0.1455 - val_acc: 0.9306\n",
            "Epoch 83/100\n",
            " - 0s - loss: 0.0519 - acc: 0.9761 - val_loss: 0.1582 - val_acc: 0.9422\n",
            "Epoch 84/100\n",
            " - 0s - loss: 0.0632 - acc: 0.9740 - val_loss: 0.0811 - val_acc: 0.9711\n",
            "Epoch 85/100\n",
            " - 0s - loss: 0.0561 - acc: 0.9761 - val_loss: 0.0979 - val_acc: 0.9682\n",
            "Epoch 86/100\n",
            " - 0s - loss: 0.0691 - acc: 0.9711 - val_loss: 0.0982 - val_acc: 0.9653\n",
            "Epoch 87/100\n",
            " - 0s - loss: 0.0644 - acc: 0.9732 - val_loss: 0.0860 - val_acc: 0.9595\n",
            "Epoch 88/100\n",
            " - 0s - loss: 0.0441 - acc: 0.9834 - val_loss: 0.0961 - val_acc: 0.9624\n",
            "Epoch 89/100\n",
            " - 0s - loss: 0.0512 - acc: 0.9805 - val_loss: 0.0788 - val_acc: 0.9653\n",
            "Epoch 90/100\n",
            " - 0s - loss: 0.0650 - acc: 0.9732 - val_loss: 0.1171 - val_acc: 0.9480\n",
            "Epoch 91/100\n",
            " - 0s - loss: 0.0639 - acc: 0.9725 - val_loss: 0.0963 - val_acc: 0.9653\n",
            "Epoch 92/100\n",
            " - 0s - loss: 0.0693 - acc: 0.9718 - val_loss: 0.1004 - val_acc: 0.9653\n",
            "Epoch 93/100\n",
            " - 0s - loss: 0.0620 - acc: 0.9711 - val_loss: 0.1028 - val_acc: 0.9538\n",
            "Epoch 94/100\n",
            " - 0s - loss: 0.0500 - acc: 0.9834 - val_loss: 0.0909 - val_acc: 0.9595\n",
            "Epoch 95/100\n",
            " - 0s - loss: 0.0476 - acc: 0.9761 - val_loss: 0.0866 - val_acc: 0.9653\n",
            "Epoch 96/100\n",
            " - 0s - loss: 0.0557 - acc: 0.9776 - val_loss: 0.0821 - val_acc: 0.9769\n",
            "Epoch 97/100\n",
            " - 0s - loss: 0.0566 - acc: 0.9754 - val_loss: 0.0603 - val_acc: 0.9855\n",
            "Epoch 98/100\n",
            " - 0s - loss: 0.0398 - acc: 0.9834 - val_loss: 0.1023 - val_acc: 0.9595\n",
            "Epoch 99/100\n",
            " - 0s - loss: 0.0624 - acc: 0.9797 - val_loss: 0.0855 - val_acc: 0.9653\n",
            "Epoch 100/100\n",
            " - 0s - loss: 0.0714 - acc: 0.9711 - val_loss: 0.0641 - val_acc: 0.9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtVV723r7Btv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c098c126-d77e-46f1-e498-0fb134e4e99b"
      },
      "cell_type": "code",
      "source": [
        "model_4_train_score = model_4.evaluate(X_train,y_train,verbose=0)\n",
        "model_4_score = model_4.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Train loss: \",model_4_train_score[0])\n",
        "print(\"Test loss: \",model_4_score[0])\n",
        "print(\"Train accuracy: %.4f%%\"% (model_4_train_score[1]*100))\n",
        "print(\"Test accuracy: %.4f%%\"%(model_4_score[1]*100))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train loss: ', 0.0284541633897437)\n",
            "('Test loss: ', 0.06408180429928564)\n",
            "Train accuracy: 99.2041%\n",
            "Test accuracy: 97.1098%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CpXIFqhF7NwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "0d9efc68-473c-4ae4-8968-7c4fbcb7795a"
      },
      "cell_type": "code",
      "source": [
        "y_pred_class = model_4.predict_classes(X_test,verbose=0)\n",
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "plot_confusion_matrix(model_4, X_test, y_test_class)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.99      0.98      0.99       240\n",
            "          1       0.94      0.94      0.94        79\n",
            "          2       0.89      1.00      0.94        17\n",
            "          3       0.91      1.00      0.95        10\n",
            "\n",
            "avg / total       0.97      0.97      0.97       346\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFlCAYAAACXw4MtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHdVJREFUeJzt3XmcHHWd//FXT8+EJBPMQSYQjjAh\nxq9LgsqGQ2DDJUpg8VpxEaKwP8GfyCGgPDBskNOVM4B4sKAgrJtd9cfiCUKWKAishIBIEPBriDmA\nQMiQ+2SmZ/aPGcKok5n8uqum0l2vp49+0F3dqf5Yj0q/U9+rCh0dHUiSlGd1WRcgSVLWDENJUu4Z\nhpKk3DMMJUm5ZxhKknLPMJQk5V592l9wwNHTnLuRsttvOobxY0dnXUZNa6iHUqkh6zJqXrHYRqmU\n+s9SrjU0jC2kte8R7zilot/7FX+8M7Xa+uJZJ0lKxPi9ds26hLIZhpKkRLyw8NWsSyibYShJSkSh\nioehGIaSpEQUCoahJCnn3l7FA/kMQ0lSIhYsWpZ1CWUzDCVJyShkNjOiYoahJCkRDqCRJOWeA2gk\nSbn39rG7ZF1C2QxDSVIiHEAjSZJ9hpKkvLPPUJKUe4ahJCn33t68c9YllM0wlCQlYsGi5VmXUDbD\nUJKUiIIr0EiS8s4+Q0lS7o1rHpV1CWUzDCVJifjT4pasSyibYShJSoQLdUuSZBhKkvLOATSSpNwb\n1zwy6xLKZhhKkhLxp8Ursi6hbIahJCkRDqCRJOWeK9BIknLPMJQk5d5eDqCRJOXdQgfQSJLyzgE0\nkqTcc9K9JCn3xu65U9YllM0wlCQlYtGSlVmXUDbDUJKUCPsMq9DZpx7DeyY2UyzWcccPHuT1FWs5\n+7RjaSuVaG1t45Jrfsiq1ev5n3v+haefXbzlz5057du0t3dkWHl1mzv3Gc7/4lWMGzcGgPHjm7nw\nnz+bcVW15+qrb2HevOeBAtOmnc4++4SsS6o5HuMe2GdYXSa9ey/2at6ZU8+7maE7DuZ73/o8z/5h\nCZde+0OWvrqC06a+j48csz93fP9B1q3fxOcuuDXrkmvKpP0mcv31F2ZdRs2aO3ceixe/zMyZN7Jg\nwRIuvvh6Zs68MeuyaorHuGc1P4AmhDAE2KXr5SsxxvXplZS+p55ZyLN/eBGAtes3MmhgA9Ov/M8t\nV3xNI9/2Z1eDUjWZM+d3HHnkQQCMGzeGNWvWsW7deoYMacy4strhMe7Z2D2HZV1C2XoNwxDCfsBN\nwDCgBSgAu4YQXgbOjDE+k36JyWtv72DT5lYAPnT0/jz6eKS9vYP37vcOzv/cB1n44nJ+MfspAAYM\nqOeKaZ9gl1HD+NUjv+c/7n4ky9Jrwp8WvMjZZ1/BmtVrOf30Ezno4H2zLqmmtLSsZO+9x295PXz4\nUFpaVub+hzpJHuOeLVqyOusSytbXleGNwKdjjH/ovjGE8LfAN4FD0yqsPxx60N58aMp+nH3hbQA8\n9sQfOf7UGZx16hROOeEw7vj+g9z07Xv5xeyn6Ojo4JYZn+WpZxby/PyXM668eo0Zsyunf+5Ejj76\n73jppVc59dP/zD333kpDQ0PWpdWsjg77uNPmMe5UzQNo+qq87i+DECDG+FugmE5J/eO9k8bzf048\ngnMv+i7rN2zm8IMnbHnvl4/8nndPaAbg7nvmsHHTG2za3MoTTy1g3NhdtrJHbYudd96JKVMmUygU\n2GOP0YwcOZxly17Puqya0tQ0gpaWt5bFWr58BU1NIzKsqPZ4jLeiUKjskaG+wvCxEMJPQwifDiF8\nsOvxmRDC/cBD/VFgGhoH78DZpx3LF758B2vWbgTgM586ivF7jQZgYhjDkpdaGLP7SK6Y9gkAinV1\nvGvCnvxp8bLM6q4F9/z8Qe64426gs6np9ddXsfPO1TtRd3t08MGTmDWrszn/uefm09Q0gsbGwRlX\nVVs8xltRxWHYazNpjPELIYRDgfcBB3ZtXgpcGmP8TdrFpeX9h72bYUMb+er0qVu2XffNn/Klsz9C\nqdTO5s2tXHLND1i5ej3Llq/ijpvOpL2jg4cfe57n4ksZVl79Dj/iAL70pev41a/m0NraxkUXnWET\nacL23XdvJkwYz9Sp51FXV2D69LOyLqnmeIx71rzn0KxLKFsh7bbuA46eZmN6ym6/6RjGjx2ddRk1\nraEeSiVDO23FYhulUi5nfPWbhoaxqV2C7XPYLRX93j/z0Gczuzz0rJMkJaMfmjpDCNcAk+nMryuB\nucD36BzH8grwqRjj5hDCVOBcoB24NcZ4W2/7rd6hP5Kk7UvKfYYhhCOAiTHGg4ApdM54uBz4Zoxx\nMvAC8OkQQiNwMXAUcDhwXgih1xFOXhlKkhLRPCb1PsNfA493PV8FNNIZdqd3bfsZcD4QgbkxxtUA\nIYRHgUO63u+RYShJSsSil9KddB9jLAFvroB2KnAvcHSMcXPXtteA0XSumLa82x99c/tWGYaSpGT0\n0/SIEMKH6QzDDwDzu1ewlT/SZ2H2GUqSklGo8LENQghHA9OBY7qaQdeFEAZ1vb0bndP/lvLWetrd\nt2+VYShJSkZdobJHH0IIQ4FrgeNijG8uAfQA8LGu5x8D7gPmAPuHEIZ13WjiEODh3vZtM6kkKRHN\nu6c+gOYEYCTwwxC23D/yFOA7IYTPAouBO2OMrSGEacD9QAdw2ZuDabbGMJQkJWLRy2tS3X+M8Vag\npxvMvr+Hz94F3LWt+zYMJUnJyHZ50YoYhpKkZGS82HYlDENJUjIMQ0lS3jXv/rasSyibYShJSsSi\npekOoEmTYShJSobNpJKkvOuo3iw0DCVJyWjerXrvdG8YSpISYZ+hJEnbsL7o9sowlCQlo3qz0DCU\nJCXE0aSSpLxr3s1J95KknFv0ytqsSyibYShJSkb1tpIahpKkhNhnKEnKPcNQkpR3zbsOybqEshmG\nkqRELHp1XdYllM0wlCQlw2ZSSVLeedcKSVLuNY/eMesSymYYSpISsWiZfYaSpLyzz1CSlHvVm4WG\noSQpIV4ZSpLyrnkXJ91vVbHYmvZX5F477axr35B1GTVteGGg53I/KBQ6PM5VzAE0vXjoJ59L+yty\nb9YrL7Hwleo9CavBobsWaawblHUZNa9YLFEq2WCVpgF1Ke7cZlJJUu7VGYaSpJyzz1CSlHsLX6ve\n7hrDUJKUDPsMJUm5Z5+hJCn3qjcLDUNJUjKad3YAjSQp5xYtX591CWUzDCVJyUhzQn/KDENJUjIc\nTSpJyrsOR5NKkvKuuckBNJKknFvU4gAaSVLeOYBGkpR79hlKkvKueWRj1iWUzTCUJCVi0esbsi6h\nbIahJCkZ/TDPMIQwEfgJcEOM8RshhAbgTuDtwFrg+BjjyhDCVOBcoB24NcZ4W2/7reLuTknSdqWu\nwkcfQgiNwNeB2d02fwZYHmM8APgBMLnrcxcDRwGHA+eFEEb0VbokSRXrKBQqemyDzcCxwNJu2z4I\nzASIMd4aY/wpcCAwN8a4Osa4EXgUOKS3HdtMKklKxNiUB9DEGNuAthBC983NwDEhhGuAV4EzgF2A\n5d0+8xowurd9G4aSpEQsXJHJAJoCEGOMl4UQLgIuBJ7q4TO9splUkpSMQqGyR3mWAQ91Pb8fmEBn\nM+ou3T6zG3/etPpXDENJUjJSHkCzFb8ApnQ9nwREYA6wfwhhWAhhCJ39hQ/3thObSSVJyUh5akUI\nYRIwg85+wtYQwvHAScDXQginAuuAU2KMG0MI0+i8UuwALosxru5t34ahJCkRY3canOr+Y4xP0jlV\n4i99vIfP3gXcta37NgwlSYlYuHJj1iWUzTCUJCXDhbolSXm3jRPnt0uGoSQpEWNHDMq6hLIZhpKk\nRCxcZZ+hJCnvbCaVJOWeA2gkSblnGEqS8m7ssIFZl1A2w/AvXD/jdp787bOU2kqcdtrHOer9vd4C\nS9vg8fse5rezf7Pl9UvzF/GVH38LgMfueZBf/eBeLvy3a7IqryZ5HveP+fMX8fmzL+NTJ3+Uk076\nUNblZG7h6k1Zl1C2ssMwhDAsxrgqyWKy9vjjTzP/hcXMnDmDVavW8PHjP++PSAIOmDKZA6ZMBmDB\nvMi8X88FYN2qNfz+0d9mWVpN8jzuHxs2bOLKr97Mge99T9albDeqeZ5hJXetuDuxKrYTkyZNZMaM\nCwHYccdGNm7cRKlUyriq2jL7P37KUSd9EIB7vvP/+MDJH8m4otrjedw/Bgxo4Fs3X86opp2yLmX7\nUVeo7JGhXq8MQwhnbOWtAp33h6opxWKRwYOLANx99ywmT96PYrGYcVW148W4kKEjR7DjiKEsePoP\nNOwwgDHv3CvrsmqO53H/qK8vUl/vcf0zVXxl2Fcz6ReAB4BXenivIflytg+//OVv+NHds7jl1q9k\nXUpNefy+h9nv/YfQ1trGrO/9mFMuOTvrkmqa57H6Wy0PoPkIcBNwToxxc/c3QgiHp1VUlh599Em+\nfesP+ddbLmfHHRuzLqemLJj3Bz58xkksXbCEtSvXcPuXbwRgzcrVzLzyX5l64ekZV1g7PI+VhZod\nQBNj/H0I4TigtYe3v5hOSdlZu3Y9M667nW9/518YOnTHrMupKatfX8kOgwZS31DPmHfuxQW3fXXL\ne1eefIFBmCDPY2WlrpJRKBnrczRpjHHDVrbX3DDA++77NatWreH8L161ZdtXr/wCo0ePyrCq2rB2\nxWqGDPOHuT94HvePZ5+dz3XXfpulS5dRX1/Pf896hBu/9uVc/wOkirsMKXR0dKT6BW+0vpDuF4hZ\nr7xEqeSU0TQduutQGuuqd0X+alEsliiVanY4wnZhQMNeqUXWsf85t6Lf+3tP3D+zOPUXVJKUiEVr\narTPUJKkbVXNzaSGoSQpEYahJCn3DENJUu41D63dSfeSJG2TxWsdQCNJyjmbSSVJuVfFN7o3DCVJ\nCTEMJUl517yjA2gkSTm3eN3mvj+0nTIMJUmJcACNJCn3CrV8CydJkrZF8xD7DCVJObd4vZPuJUk5\nZ5+hJCn3qjgLDUNJUjJcgUaSlHt7OoBGkpR3SxxAI0nKu0IVt5MahpKkRDiaVJKUe4ahJCn3xjQ6\ngEaSlHMvbnAAjSQp52wmlSTlXhUPJjUMJUnJ2MM+Q0lS3r1kn6EkKe/64+a+IYSJwE+AG2KM3wgh\n7AF8F2gAWoFPxhhfDSFMBc4F2oFbY4y39bbfKr4vsSRpe1IoFCp69CWE0Ah8HZjdbfNX6Ay7w4Af\nAV/o+tzFwFHA4cB5IYQRve3bMJQkJaJQqOyxDTYDxwJLu207A/ivrufLgZ2AA4G5McbVMcaNwKPA\nIb3t2GZSSVIidh+c7gCaGGMb0BZC6L5tPUAIoQicCVwO7EJnML7pNWB0b/s2DCVJiXh5YzYDaLqC\n8HvAL2OMs0MIJ/3FR/q87rSZVJKUiH5oJt2a7wLzY4yXdb1eSufV4Zt248+bVv9K6leG9cW2tL8i\n9wqFDooe55S1U1es3mHj1aJQqPc3o4plsQJN16jRN2KMl3TbPAf4TghhGNBGZ3/hub3tJ/UwLJV2\nSPsrcu+Y3XanVLLFO01tLGPjGx7jtA0e0Eh7qSHrMmpaXYrtgWmvQBNCmATMAJqB1hDC8cAoYFMI\n4cGujz0XYzwjhDANuB/oAC6LMa7ubd/+7ZYkJWL3QakPoHmSzqkS2/LZu4C7tnXfhqEkKRFLN1Vv\nV4JhKElKRKHQkXUJZTMMJUmJqObpCYahJCkRuw/0rhWSpJxbutk+Q0lSztXZZyhJyjv7DCVJuZf2\npPs0GYaSpETs6gAaSVLeveoAGklS3hVwAI0kKefsM5Qk5d7oHewzlCTl3DL7DCVJeWczqSQp9wxD\nSVLuuQKNJCn3dnHSvSQp75Zt3ph1CWUzDCVJibDPUJKUe4ahJCn36lyOTZKUdzu7Ao0kKe+Wv+EK\nNJKknLPPUJKUe4ahJCn3Rg2wz1CSlHMtbzjpXpKUczaTSpJyzzCUJOWed62QJOXeSAfQSJLy7vVW\nB9BIknLOPsMacfXVtzBv3vNAgWnTTmeffULWJdUkj3N6Xpj/Il8893pO+uQxnHDiB/jS+V9j5cq1\nAKxZvY593vV2pl98WsZV1gbP479WMAyr39y581i8+GVmzryRBQuWcPHF1zNz5o1Zl1VzPM7p2bhh\nE9dedScHHDhhy7arrztny/PLLr6VD3/0iCxKqzmexz2r5gE021R7COGv8j6EsHvy5WRnzpzfceSR\nBwEwbtwY1qxZx7p16zOuqvZ4nNPTMKCBr33zAkY2Df+r9xYtWsq6teuZuM+4DCqrPZ7HPRs5YGBF\njyz1emUYQvgocCMwOIRwL3BWjHFt19v/BhyZcn39pqVlJXvvPX7L6+HDh9LSspIhQxozrKr2eJzT\nU19fpL6+2ON73595Pyec+IF+rqh2eR73bEUVD6Dp68pwGrAvsDPwKDArhDC0670qbh3uW0dH9d6k\nspp4nNPX2trG756K7HfAhL4/rLJ4HneqK1T2yFJffYalGOOKrue3hhCWAfeHEI6DKr6lcQ+amkbQ\n0rJiy+vly1fQ1DQiw4pqk8e5/z35xPNMmGjzaJI8j3uWdaBVoq8rw0dCCD8PIQwCiDH+BLgEmA28\nI+3i+tPBB09i1qxHAHjuufk0NY2gsXFwxlXVHo9z/3vu2T8x/h1jsi6jpnge92yn+kEVPbLU65Vh\njPGCEMLhwKZu2+4PIfwGOCHl2vrVvvvuzYQJ45k69Tzq6gpMn35W1iXVJI9zep5/biE3zJjJK0uX\nU19fZPYDj3Pt9efSsnwV79m3pv7tmjnP456taqvePsNC2m3dra0La6o5dXtULLZRKjlLJk1tLKPN\nY5y6wQMaaS9V75Je1aChYWxqjZnXPD27ot/7C979vswaWv3bLUlKRDX3GRqGkqREGIaSpNwbkfEg\nmEoYhpKkRKwupTeAJoQwhM7FXoYDOwCXAa8CN9M51W9ejPFz5e6/mpeSkyRtR1KedP9PQIwxHgEc\nD3yNzhXSzokxHgIMDSEcU3bt5f5BSZK6KxQ6Knr0oQXYqev5cGAFMDbGOLdr28+Ao8qt3TCUJCWi\nWOGjNzHG7wNjQggvAL8GzgdWdvvIa8Docmu3z1CSlIhhKQ6gCSF8ElgSY5wSQng38CNgdbePVDSW\n1TCUJCViTYoDaIBDgPsBYoxPdy0T2tDt/d2ApeXu3GZSSVIi6ip89OEF4ECAEMKewFrg+RDC33W9\n/w/AfeXW7pWhJCkRdX0PgqnELcDtIYSH6Myu0+mcWnFLCKEOmBNjfKDcnRuGkqREDE2xzzDGuA74\nxx7empzE/g1DSVIi1qXbZ5gqw1CSlAjXJpUk5Z5hKEnKPcNQkpR7Oxar98bMhqEkKREb2h1AI0nK\nuWpexcUwlCQlomCfoSQp74qGoSQp74YU01uBJm2GoSQpERvaN2RdQtkMQ0lSIpxnKEnKPcNQkpR7\ng+sGZ11C2QxDSVIiNnXYZyhJyjmnVkiSci/lO92nyjCUJCXC5dgkSbk3yAE0kqS82+wAGklS3jmA\nRpKUewUH0EiS8s4VaCRJuTew4ACarSoW29L+itwrFDo8zilra++g3mOcvkI7dcXNWVehMr2BA2i2\nqlTy4jNtxWKbxzllOxRHeoz7Qal9NW2l6u13qgaDB6S3b+cZSpJyr2CfoSQp7wZgn6EkKeda7TOU\nJOVdFbeSGoaSpGQ4z1CSlHsFqncksGEoSUpEgwNoJEl511ZwAI0kKeequMvQMJQkJcNJ95Kk3LPP\nUJKUe1V8YWgYSpKSUXIFGklS3lVzn2E133FDkqREeGUoSUpEfYcDaCRJOdfupHtJUt5Vc5+hYShJ\nSkQVZ6FhKElKRqHgXSskSTlXdACNJCnv+mMATQhhEPB74ApgNvA9oAi8Anwqxri5nP06z1CSlIhC\nobLHNroIWNH1/HLgmzHGycALwKfLrd0wlCQloq7CR19CCO8E9gbu6dp0OPDTruc/A44qt3abSSVJ\niSimf9eKGcBZwCldrxu7NYu+Bowud8eGoSQpEWn2GYYQTgZ+E2NcGELo6SMVzewwDCVJiUh5nuHf\nA3uFEI4Ddgc2A+tCCINijBuB3YCl5e7cMJQkJSLNFWhijCe8+TyEcCmwCDgY+Bjw713/va/c/TuA\nRpKUiEKFjzJcApwSQngYGAHcWW7tXhlKkhLRX5PuY4yXdnv5/iT2aRhKkhLRUeddKyRJOedC3ZKk\n3HOhbklS7nllKEnKvUJHY9YllM0w7Obqq29h3rzngQLTpp3OPvv0uMqBKuRxTp/HOD0vzF/CeZ+/\niqmfOo5PnHQsr77awkUX3kR7ezsjRw7jK1eew4ABDVmXmY269VlXULb/73mGIYSRaRSStblz57F4\n8cvMnHkjl19+HldddXPWJdUkj3P6PMbp2bhhE1df+R0OOHCfLdtu/sb3OeETU7j9zq+wx5jR/PhH\nszOsMFsZzDNMTK9hGEL4+xBCDCE8EEKYGEJ4GngohLAohHBsP9XYL+bM+R1HHnkQAOPGjWHNmnWs\nW1e9/8rZXnmc0+cxTk/DgAa+/q3pNI0asWXbE088y2FH7A/AoYftx5zH5mVVXubSvmtFmvr6/ovo\nnNB4KfBz4OQY4wTgwK5tNaOlZSUjRgzb8nr48KG0tKzMsKLa5HFOn8c4PfX1RQYO3OHPtm3cuGlL\ns+iInYbSsnxVFqVtHzoaK3tkqK8+w80xxiXAkhDCyzHGpwFijMtCCJvSLy87HR3VO0S4mnic0+cx\n7j+5P9Y13Ge4LIRwPkCM8RCAEMLuIYQbgBfTLq4/NTWNoKVlxZbXy5evoKlpRC9/QuXwOKfPY9y/\nBg8ayKZNnbfUe23ZCppGDc+4ouwUKvxflvoKw38ClvzFtlHAYuDUNArKysEHT2LWrEcAeO65+TQ1\njaCxsX/W2csTj3P6PMb968D3vovZ//0YALMfeIyDD9k344qyVL1DaAppX9a3ti6smnaDG264nSee\neIa6ugLTp5/FO9+5V9YlbZNisY1SqXpmyVTjcfYY94+OutW0bcfH+blnF3D9dXeydOlr1NcXGTVq\nJ7561TlcfNE3eOONVkaPbuLSK86koWH7/f8weMDE1FJn5eb7Kvq9H77DlMwS0TCsAdX2Q12NPMb9\nY3sPw1qQZhiu2PBwRb/3IwZPziwMPeskSYkoFL1rhSQp57IeBFMJw1CSlBDDUJKUc4VC1uvIlM8w\nlCQloqNUvVN4DENJUiIKxY1Zl1A2w1CSlAgH0EiScs8wlCTlnn2GkqTcKxSr92ZGhqEkKRGFgs2k\nkqTcMwwlSTnnABpJUu61lwZVtoOGZOooh2EoSUpEXXFz1iWUzTCUJCWiehtJDUNJUkIcTSpJEt61\nQpKUcx2lgZXtIMNEMgwlSYlwAI0kSVU8hMYwlCQlwgE0kqTcK5V2qGwHxWTqKIdhKElKRLH4RtYl\nlM0wlCQlouDUCkmS7DOUJOWcd62QJOVee2lAZTtwAI0kqdoVi61Zl1A2w1CSlBAH0EiScs4+Q0mS\nXIFGkpR3pVJDRX++2EcrawjhBuC9QAdwToxxbkVf2I1hKElKRLHYltq+QwiHAeNjjAeFEP4GuB04\nKKn9V29vpyRpu1KgrqJHH94H/Bggxvg8MDyE8LakavfKUJKUiEqbSet6z8NdgCe7vV7etW1NRV/a\nJfUwbGgYW709qlWkj5NICfAY948BGU68VmX6+fc+0e/yr7ckqRospfNK8E27Aq8ktXPDUJJUDWYB\nxwOEEP4WWBpjXJvUzgsdHR1J7UuSpNSEEK4CDgXagTNjjE8ntW/DUJKUezaTSpJyzzCUJOWe8wy7\nSXOpH70lhDAR+AlwQ4zxG1nXU4tCCNcAk+n8O35ljPHujEuqKSGEwcAdwM7AQOCKGOPPMy1KFfHK\nsEv3pX6AU4GbMi6pJoUQGoGvA7OzrqVWhRCOACZ2nctTgBszLqkWfRB4IsZ4GPCPwPUZ16MKGYZv\nSXWpH22xGTiWzjlDSsevgY93PV8FNIYQnMqeoBjjD2KM13S93AN4Kct6VDmbSd+S6lI/6hRjbAPa\nQghZl1KzYowlYH3Xy1OBe7u2KWEhhP8BdgeOy7oWVcYrw61zGTlVtRDCh+kMw7OyrqVWxRgPBj4E\n/HsIwd+MKmYYviXVpX6k/hRCOBqYDhwTY1yddT21JoQwKYSwB0CM8Xd0trI1ZVuVKmEYviXVpX6k\n/hJCGApcCxwXY1yRdT016lDgiwAhhJ2BIUBLphWpIq5A002aS/2oUwhhEjADaAZagZeBf/BHOzkh\nhP8LXAr8sdvmk2OMS7KpqPaEEAYBt9E5eGYQcFmM8WfZVqVKGIaSpNyzmVSSlHuGoSQp9wxDSVLu\nGYaSpNwzDCVJuWcYSpJyzzCUJOWeYShJyr3/Ba6IZvum9qkmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f50618aa950>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oxqI7ESU7SN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}